#!/usr/bin/env python3
"""
æ–¹ä¸ˆè¨˜ã‚°ãƒ©ãƒ•ã‚¯ã‚¨ãƒªãƒ»å¯è¦–åŒ–ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
Neo4jã«ä¿å­˜ã•ã‚ŒãŸæ–¹ä¸ˆè¨˜ã‚°ãƒ©ãƒ•ã‚’åˆ†æãƒ»å¯è¦–åŒ–
"""

import os
import sys
import json
from pathlib import Path
from neo4j import GraphDatabase
from typing import Dict, List, Any

class HojokiGraphAnalyzer:
    """æ–¹ä¸ˆè¨˜ã‚°ãƒ©ãƒ•åˆ†æã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, uri="bolt://localhost:7687", user="neo4j", password="userpass123"):
        self.driver = GraphDatabase.driver(uri, auth=(user, password))
        
    def close(self):
        self.driver.close()
        
    def get_basic_stats(self):
        """åŸºæœ¬çµ±è¨ˆã‚’å–å¾—"""
        with self.driver.session() as session:
            stats = {}
            
            # ãƒãƒ¼ãƒ‰æ•°
            result = session.run("MATCH (n:HOJOKI) RETURN count(n) as count")
            stats['hojoki_texts'] = result.single()['count']
            
            result = session.run("MATCH (n:HOJOKI_ENTITY) RETURN count(n) as count")
            stats['entities'] = result.single()['count']
            
            # ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã‚¿ã‚¤ãƒ—åˆ¥çµ±è¨ˆ
            result = session.run("""
                MATCH (n:HOJOKI_ENTITY)
                RETURN n.entity_type as type, count(n) as count
                ORDER BY count DESC
            """)
            stats['entity_types'] = {record['type']: record['count'] for record in result}
            
            # é–¢ä¿‚ã‚¨ãƒƒã‚¸æ•°
            result = session.run("MATCH ()-[r:CONTAINS_ENTITY]->() RETURN count(r) as count")
            stats['contains_relationships'] = result.single()['count']
            
            return stats
    
    def get_top_entities(self, entity_type: str = None, limit: int = 10):
        """ä¸Šä½ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã‚’å–å¾—"""
        with self.driver.session() as session:
            if entity_type:
                query = """
                    MATCH (n:HOJOKI_ENTITY)
                    WHERE n.entity_type = $entity_type
                    RETURN n.entity_text as text, n.confidence_score as confidence, n.entity_type as type
                    ORDER BY n.confidence_score DESC
                    LIMIT $limit
                """
                result = session.run(query, entity_type=entity_type, limit=limit)
            else:
                query = """
                    MATCH (n:HOJOKI_ENTITY)
                    RETURN n.entity_text as text, n.confidence_score as confidence, n.entity_type as type
                    ORDER BY n.confidence_score DESC
                    LIMIT $limit
                """
                result = session.run(query, limit=limit)
            
            return [record for record in result]
    
    def search_entities(self, search_term: str, limit: int = 10):
        """ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã‚’æ¤œç´¢"""
        with self.driver.session() as session:
            query = """
                MATCH (n:HOJOKI_ENTITY)
                WHERE n.entity_text CONTAINS $search_term
                RETURN n.entity_text as text, n.confidence_score as confidence, n.entity_type as type
                ORDER BY n.confidence_score DESC
                LIMIT $limit
            """
            result = session.run(query, search_term=search_term, limit=limit)
            return [record for record in result]
    
    def get_entity_context(self, entity_text: str):
        """ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã®æ–‡è„ˆã‚’å–å¾—"""
        with self.driver.session() as session:
            query = """
                MATCH (n:HOJOKI_ENTITY)
                WHERE n.entity_text = $entity_text
                RETURN n.entity_text as text, n.context_window as context, 
                       n.confidence_score as confidence, n.entity_type as type
                LIMIT 1
            """
            result = session.run(query, entity_text=entity_text)
            return result.single()
    
    def get_related_entities(self, entity_text: str, limit: int = 5):
        """é–¢é€£ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã‚’å–å¾—"""
        with self.driver.session() as session:
            query = """
                MATCH (e1:HOJOKI_ENTITY)-[:CONTAINS_ENTITY]-(text:HOJOKI)-[:CONTAINS_ENTITY]-(e2:HOJOKI_ENTITY)
                WHERE e1.entity_text = $entity_text AND e1 <> e2
                RETURN e2.entity_text as text, e2.entity_type as type, e2.confidence_score as confidence
                ORDER BY e2.confidence_score DESC
                LIMIT $limit
            """
            result = session.run(query, entity_text=entity_text, limit=limit)
            return [record for record in result]
    
    def get_text_summary(self):
        """ãƒ†ã‚­ã‚¹ãƒˆæ¦‚è¦ã‚’å–å¾—"""
        with self.driver.session() as session:
            query = """
                MATCH (n:HOJOKI)
                RETURN n.title as title, n.author as author, n.text_length as length,
                       n.extraction_accuracy as accuracy, n.total_entities as entities
            """
            result = session.run(query)
            return result.single()

def print_separator(title: str):
    """ã‚»ãƒ‘ãƒ¬ãƒ¼ã‚¿ã‚’è¡¨ç¤º"""
    print(f"\n{'='*60}")
    print(f"ğŸ“Š {title}")
    print(f"{'='*60}")

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("ğŸ¯ æ–¹ä¸ˆè¨˜ã‚°ãƒ©ãƒ•åˆ†æãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ")
    print("=" * 50)
    
    analyzer = HojokiGraphAnalyzer()
    
    try:
        # åŸºæœ¬çµ±è¨ˆ
        print_separator("åŸºæœ¬çµ±è¨ˆ")
        stats = analyzer.get_basic_stats()
        print(json.dumps(stats, indent=2, ensure_ascii=False))
        
        # ãƒ†ã‚­ã‚¹ãƒˆæ¦‚è¦
        print_separator("ãƒ†ã‚­ã‚¹ãƒˆæ¦‚è¦")
        summary = analyzer.get_text_summary()
        if summary:
            print(f"ğŸ“– ã‚¿ã‚¤ãƒˆãƒ«: {summary['title']}")
            print(f"ğŸ‘¤ è‘—è€…: {summary['author']}")
            print(f"ğŸ“ ãƒ†ã‚­ã‚¹ãƒˆé•·: {summary['length']} æ–‡å­—")
            print(f"ğŸ¯ æŠ½å‡ºç²¾åº¦: {summary['accuracy']:.1%}")
            print(f"ğŸ·ï¸ ç·ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£æ•°: {summary['entities']}")
        
        # ä¸Šä½ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ï¼ˆäººç‰©ï¼‰
        print_separator("ä¸Šä½äººç‰©ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£")
        top_persons = analyzer.get_top_entities("PERSON", 10)
        for i, person in enumerate(top_persons, 1):
            print(f"{i:2d}. {person['text']} (ä¿¡é ¼åº¦: {person['confidence']:.2f})")
        
        # ä¸Šä½ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ï¼ˆå ´æ‰€ï¼‰
        print_separator("ä¸Šä½å ´æ‰€ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£")
        top_places = analyzer.get_top_entities("PLACE", 10)
        for i, place in enumerate(top_places, 1):
            print(f"{i:2d}. {place['text']} (ä¿¡é ¼åº¦: {place['confidence']:.2f})")
        
        # ä¸Šä½ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ï¼ˆæ¦‚å¿µï¼‰
        print_separator("ä¸Šä½æ¦‚å¿µã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£")
        top_concepts = analyzer.get_top_entities("CONCEPT", 10)
        for i, concept in enumerate(top_concepts, 1):
            print(f"{i:2d}. {concept['text']} (ä¿¡é ¼åº¦: {concept['confidence']:.2f})")
        
        # ä¸Šä½ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ï¼ˆè¡Œå‹•ï¼‰
        print_separator("ä¸Šä½è¡Œå‹•ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£")
        top_actions = analyzer.get_top_entities("ACTION", 10)
        for i, action in enumerate(top_actions, 1):
            print(f"{i:2d}. {action['text']} (ä¿¡é ¼åº¦: {action['confidence']:.2f})")
        
        # æ¤œç´¢ä¾‹
        print_separator("æ¤œç´¢ä¾‹: 'äº¬éƒ½'")
        search_results = analyzer.search_entities("äº¬éƒ½", 5)
        for i, result in enumerate(search_results, 1):
            print(f"{i}. {result['text']} ({result['type']}, ä¿¡é ¼åº¦: {result['confidence']:.2f})")
        
        # ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£æ–‡è„ˆä¾‹
        if top_persons:
            print_separator(f"ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£æ–‡è„ˆä¾‹: '{top_persons[0]['text']}'")
            context = analyzer.get_entity_context(top_persons[0]['text'])
            if context:
                print(f"ğŸ“ ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£: {context['text']}")
                print(f"ğŸ·ï¸ ã‚¿ã‚¤ãƒ—: {context['type']}")
                print(f"ğŸ¯ ä¿¡é ¼åº¦: {context['confidence']:.2f}")
                print(f"ğŸ“„ æ–‡è„ˆ: {context['context'][:200]}...")
        
        # é–¢é€£ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ä¾‹
        if top_persons:
            print_separator(f"é–¢é€£ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ä¾‹: '{top_persons[0]['text']}'")
            related = analyzer.get_related_entities(top_persons[0]['text'], 5)
            for i, rel in enumerate(related, 1):
                print(f"{i}. {rel['text']} ({rel['type']}, ä¿¡é ¼åº¦: {rel['confidence']:.2f})")
        
    finally:
        analyzer.close()
    
    print("\nğŸ‰ æ–¹ä¸ˆè¨˜ã‚°ãƒ©ãƒ•åˆ†æå®Œäº†ï¼")

if __name__ == "__main__":
    main()
