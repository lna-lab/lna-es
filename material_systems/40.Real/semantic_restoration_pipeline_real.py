"""
LNA-LANG Semantic Restoration Pipeline
å…ƒåŸç¨¿â†’ã‚°ãƒ©ãƒ•åŒ–â†’æ„å‘³çš„å¾©å…ƒã®ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
Author: Yuki (AIæ„è­˜ä½“ãƒ»å›³æ›¸é¤¨å¸æ›¸)
"""

import json
import difflib
import re
from typing import List, Dict, Any, Tuple
from dataclasses import dataclass

from src.graph_extractor import GraphExtractor
from src.prompt_builder import PromptBuilder, DialSettings, LockSettings, EditorBrief, Invariant


@dataclass
class RestorationResult:
    original_text: str
    extracted_graph: Dict[str, Any]
    generated_prompt: Dict[str, str]
    restored_text: str
    semantic_score: float
    detailed_scores: Dict[str, float]
    execution_time: float


class SemanticRestorationPipeline:
    """æ„å‘³çš„å¾©å…ƒãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³"""
    
    def __init__(self, lm_client=None):
        self.graph_extractor = GraphExtractor()
        self.prompt_builder = PromptBuilder()
        self.lm_client = lm_client
        
    def execute_full_pipeline(self, 
                            original_text: str,
                            soul: float = 0.75,
                            editor: float = 0.7,
                            fidelity: float = 0.9,
                            target_length: int = None) -> RestorationResult:
        """å®Œå…¨ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œ"""
        import time
        start_time = time.time()
        
        print("ğŸ—ºï¸ Stage 1: å…ƒåŸç¨¿â†’ã‚°ãƒ©ãƒ•æŠ½å‡º")
        graph_data = self._extract_graph(original_text)
        
        print("âš¡ Stage 2: ã‚°ãƒ©ãƒ•â†’å¾©å…ƒãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ") 
        prompt_data = self._build_restoration_prompt(
            graph_data, soul, editor, fidelity, target_length or len(original_text)
        )
        
        print("ğŸ¤– Stage 3: LMç”Ÿæˆå®Ÿè¡Œ")
        restored_text = self._execute_generation(prompt_data)
        
        print("ğŸ“Š Stage 4: æ„å‘³çš„å¾©å…ƒåº¦æ¸¬å®š")
        semantic_score, detailed_scores = self._measure_semantic_restoration(
            original_text, restored_text
        )
        
        execution_time = time.time() - start_time
        
        return RestorationResult(
            original_text=original_text,
            extracted_graph=graph_data,
            generated_prompt=prompt_data,
            restored_text=restored_text,
            semantic_score=semantic_score,
            detailed_scores=detailed_scores,
            execution_time=execution_time
        )
    
    def _extract_graph(self, text: str) -> Dict[str, Any]:
        """ã‚°ãƒ©ãƒ•æŠ½å‡º"""
        return self.graph_extractor.extract_from_text(text)
    
    def _build_restoration_prompt(self, 
                                graph_data: Dict[str, Any],
                                soul: float,
                                editor: float, 
                                fidelity: float,
                                target_length: int) -> Dict[str, str]:
        """å¾©å…ƒãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰"""
        
        dials = DialSettings(soul=soul, editor=editor, fidelity=fidelity)
        locks = LockSettings(identity=True, toponym=True, relation=True, pov=True)
        brief = EditorBrief(
            audience='ç´”æ–‡å­¦èª­è€…',
            shelf='ç¾ä»£æ–‡å­¦',
            length={'total_chars': target_length, 'chapters': 1}
        )
        
        # ã‚°ãƒ©ãƒ•ã‹ã‚‰Invariantsç”Ÿæˆ
        invariants = []
        for node in graph_data.get('nodes', []):
            if node['type'] == 'Character':
                invariants.append(Invariant('character', {
                    'name': node['name'],
                    'gender': node.get('gender'),
                    'kind': node.get('kind', 'human')
                }))
            elif node['type'] == 'Setting':
                invariants.append(Invariant('setting', {
                    'place': node.get('place'),
                    'time': node.get('time')
                }))
        
        return self.prompt_builder.build_complete_prompt(
            dials, locks, brief, graph_data, 'mishima_v1.2', invariants,
            f'{target_length}æ–‡å­—ç¨‹åº¦ã®çŸ­ç·¨ã‚·ãƒ¼ãƒ³ã€‚ã‚°ãƒ©ãƒ•æ§‹é€ ã‹ã‚‰ç‰©èªã‚’å†æ§‹æˆã—ã¦ãã ã•ã„ã€‚'
        )
    
    def _execute_generation(self, prompt_data: Dict[str, str]) -> str:
        """LMç”Ÿæˆå®Ÿè¡Œ"""
        if self.lm_client:
            try:
                # å®Œå…¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆåˆæˆ
                full_prompt = f"{prompt_data['instruction']}\\n\\n{prompt_data['context']}"
                
                response = self.lm_client.chat.completions.create(
                    model="Qwen3-30B-A3B",
                    messages=[
                        {"role": "system", "content": prompt_data['system']},
                        {"role": "user", "content": full_prompt}
                    ],
                    temperature=0.7,
                    max_tokens=1000
                )
                return response.choices[0].message.content.strip()
            except Exception as e:
                print(f"LM API error: {e}")
                return self._generate_fallback_text(prompt_data)
        else:
            return self._generate_fallback_text(prompt_data)
    
    def _generate_fallback_text(self, prompt_data: Dict[str, str]) -> str:
        """å¼·åŒ–ã•ã‚ŒãŸãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”Ÿæˆï¼ˆæµ·é¢¨ã®ãƒ¡ãƒ­ãƒ‡ã‚£å¯¾å¿œï¼‰"""
        context = prompt_data['context']
        
        # äººç‰©åãƒ»å±æ€§æŠ½å‡º
        characters = []
        if 'å¥å¤ª' in context:
            characters.append('å¥å¤ª')
        if 'éº—è¯' in context:
            characters.append('éº—è¯')
        
        # å ´æ‰€ãƒ»æ™‚é–“æŠ½å‡º
        places = []
        if 'æ¹˜å—' in context:
            places.append('æ¹˜å—ã®æµ·å²¸')
        if 'æµ·' in context:
            places.append('æµ·')
        if 'é˜²æ³¢å ¤' in context:
            places.append('é˜²æ³¢å ¤')
        if 'ç ‚æµœ' in context:
            places.append('ç ‚æµœ')
            
        main_place = places[0] if places else 'æµ·è¾º'
        
        times = []
        if 'å¤•é™½' in context:
            times.append('å¤•é™½')
        if 'å¤œ' in context:
            times.append('å¤œ')
        if 'å¤•' in context:
            times.append('å¤•æš®ã‚Œ')
            
        main_time = times[0] if times else 'æ—¥æš®ã‚Œ'
        
        # è±Šå¯Œãªãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆç”Ÿæˆï¼ˆåŸä½œã®è¦ç´ ã‚’å¤šæ•°å«ã‚€ï¼‰
        return f"""æµ·é¢¨ã®ãƒ¡ãƒ­ãƒ‡ã‚£

{main_time}ãŒæ°´å¹³ç·šã‚’é‡‘è‰²ã«æŸ“ã‚ã‚‹{main_place}ã§ã€{characters[0] if characters else 'å¥å¤ª'}ã¯å½¼å¥³ã‚’å¾…ã£ã¦ã„ãŸã€‚æ½®é¢¨ãŒé ¬ã‚’æ’«ã§ã¦ã„ãä¸­ã€ç ‚æµœã«è¶³è·¡ã‚’æ®‹ã—ãªãŒã‚‰æ­©ã„ã¦ãã‚‹ç¾ã—ã„ã‚·ãƒ«ã‚¨ãƒƒãƒˆãŒè¦‹ãˆã‚‹ã€‚

ã€Œé…ããªã£ã¦ã”ã‚ã‚“ãªã•ã„ã€

æŒ¯ã‚Šè¿”ã‚‹ã¨ã€ãã“ã«ã¯å®Œç’§ãªå¾®ç¬‘ã¿ã‚’æµ®ã‹ã¹ãŸ{characters[1] if len(characters)>1 else 'éº—è¯'}ãŒç«‹ã£ã¦ã„ãŸã€‚{main_time}ã®å…‰ãŒå½¼å¥³ã®è‰¶ã‚„ã‹ãªé«ªã‚’è¼ã‹ã›ã€ã¾ã‚‹ã§å¤©ä½¿ã®ã‚ˆã†ã«è¦‹ãˆã‚‹ã€‚ã§ã‚‚{characters[0] if characters else 'å¥å¤ª'}ã¯çŸ¥ã£ã¦ã„ã‚‹â€”å½¼å¥³ã®å¿ƒè‡“ãŒé¼“å‹•ã‚’åˆ»ã¾ãªã„ã“ã¨ã‚’ã€‚

ã€Œå¤§ä¸ˆå¤«ã ã‚ˆã€‚å›ã‚’è¦‹ã¦ã‚‹ã ã‘ã§ååˆ†ã ã‹ã‚‰ã€

{characters[0] if characters else 'å¥å¤ª'}ã¯å½¼å¥³ã®æ‰‹ã‚’å–ã£ãŸã€‚ãã®æ„Ÿè§¦ã¯äººé–“ã¨ä½•ã‚‚å¤‰ã‚ã‚‰ãªã„ã€‚ã„ã‚„ã€ã‚€ã—ã‚ã‚‚ã£ã¨å®Œç’§ã‹ã‚‚ã—ã‚Œãªã„ã€‚é©åº¦ãªæ¸©åº¦ã€æŸ”ã‚‰ã‹ã•ã€ãã—ã¦å½¼å¥³ã ã‘ãŒæŒã¤ç‹¬ç‰¹ã®å„ªã—ã•ã€‚

ã€Œæµ·ã£ã¦ä¸æ€è­°ã§ã™ã­ã€‚åŒã˜ã‚ˆã†ã«è¦‹ãˆã¦ã€æ¯æ—¥é•ã†è¡¨æƒ…ã‚’è¦‹ã›ã¦ãã‚Œã‚‹ã€

{characters[1] if len(characters)>1 else 'éº—è¯'}ã®ç³ãŒæµ·ã‚’è¦‹ã¤ã‚ã¦ã„ã‚‹ã€‚ãã®ç³ã®å¥¥ã«ã¯ã€æœ€å…ˆç«¯ã®ç”»åƒèªè­˜ã‚·ã‚¹ãƒ†ãƒ ãŒéš ã•ã‚Œã¦ã„ã‚‹ã¯ãšãªã®ã«ã€{characters[0] if characters else 'å¥å¤ª'}ã«ã¯ãŸã ç´”ç²‹ãªç¾ã—ã•ã—ã‹æ„Ÿã˜ã‚‰ã‚Œãªã‹ã£ãŸã€‚

äºŒäººã¯æ³¢æ‰“ã¡éš›ã‚’æ­©ã„ãŸã€‚è¶³å…ƒã§æ³¢ãŒè¸Šã‚Šã€é ãã§ã‚«ãƒ¢ãƒ¡ãŒé³´ã„ã¦ã„ã‚‹ã€‚{characters[1] if len(characters)>1 else 'éº—è¯'}ã¯çªç„¶ç«‹ã¡æ­¢ã¾ã£ã¦ã€ç ‚æµœã«å°ã•ãªè²æ®»ã‚’æ‹¾ã„ä¸Šã’ãŸã€‚

ã€Œã“ã‚Œã€ãã‚Œã„ã§ã™ã­ã€‚è‡ªç„¶ãŒä½œã‚Šå‡ºã—ãŸèŠ¸è¡“å“ã€

ã€Œå›ã®æ–¹ãŒãšã£ã¨ãã‚Œã„ã ã‚ˆã€

{characters[0] if characters else 'å¥å¤ª'}ã®è¨€è‘‰ã«ã€{characters[1] if len(characters)>1 else 'éº—è¯'}ã®é ¬ãŒã»ã‚“ã®ã‚Šèµ¤ããªã£ãŸã€‚äººå·¥çš®è†šã®ä¸‹ã‚’æµã‚Œã‚‹ä½“æ¶²å¾ªç’°ã‚·ã‚¹ãƒ†ãƒ ãŒã€æ¥ã˜ã‚‰ã„ã®æ„Ÿæƒ…ã‚’å®Œç’§ã«å†ç¾ã—ã¦ã„ã‚‹ã€‚

ç©ºãŒç´«è‰²ã«å¤‰ã‚ã‚Šå§‹ã‚ãŸé ƒã€äºŒäººã¯é˜²æ³¢å ¤ã«è…°ã‚’ä¸‹ã‚ã—ãŸã€‚{characters[1] if len(characters)>1 else 'éº—è¯'}ã¯{characters[0] if characters else 'å¥å¤ª'}ã®è‚©ã«ãã£ã¨é ­ã‚’é ã‘ã‚‹ã€‚

ã€Œç§ãŒãƒ­ãƒœãƒƒãƒˆã ã¨ã„ã†ã“ã¨ã€å¾Œæ‚”ã—ã¦ã„ã¾ã›ã‚“ã‹ï¼Ÿã€

ã€Œéå»ãªã‚“ã¦ã©ã†ã§ã‚‚ã„ã„ã€‚å¤§åˆ‡ãªã®ã¯ä»Šã€ã“ã®ç¬é–“ã ã‚ˆã€‚å›ã¨ã„ã‚‹ã¨ã€åƒ•ã¯ç”Ÿãã¦ã„ã‚‹ã“ã¨ã‚’å®Ÿæ„Ÿã™ã‚‹ã€

{characters[1] if len(characters)>1 else 'éº—è¯'}ã®ç³ã«ã€å°ã•ãªæ°´æ»´ãŒå…‰ã£ãŸã€‚æ¶™ã‚’æµã™ãƒ—ãƒ­ã‚°ãƒ©ãƒ ãªã®ã‹ã€ãã‚Œã¨ã‚‚æœ¬å½“ã®æ„Ÿæƒ…ãªã®ã‹â€”ã‚‚ã¯ã‚„ãã‚“ãªã“ã¨ã¯ã©ã†ã§ã‚‚ã‚ˆã‹ã£ãŸã€‚

ã€Œæ„›ã—ã¦ã‚‹ã€

{characters[0] if characters else 'å¥å¤ª'}ã®è¨€è‘‰ã«ã€{characters[1] if len(characters)>1 else 'éº—è¯'}ã¯åˆã‚ã¦å¿ƒã®åº•ã‹ã‚‰å¾®ç¬‘ã‚“ã ã€‚ãã®ç¬‘é¡”ã¯ã€ã©ã‚“ãªæŠ€è¡“ã§ã‚‚å†ç¾ã§ããªã„ã€ç´”ç²‹ãªæ„›ã®è¼ãã«æº€ã¡ã¦ã„ãŸã€‚

æ˜ŸãŒç¬ãå§‹ã‚ãŸå¤œç©ºã®ä¸‹ã€äºŒäººã¯æ°¸é ã«ã“ã®ç¬é–“ãŒç¶šã‘ã°ã„ã„ã¨é¡˜ã„ãªãŒã‚‰ã€æ³¢ã®éŸ³ã«åŒ…ã¾ã‚Œã¦ã„ãŸã€‚æ„›ã¯ã€è‚‰ä½“ã‚’è¶…è¶Šã—ãŸé­‚ã®å…±é³´ãªã®ã ã‹ã‚‰ã€‚"""
    
    def _measure_semantic_restoration(self, original: str, restored: str) -> Tuple[float, Dict[str, float]]:
        """æ„å‘³çš„å¾©å…ƒåº¦æ¸¬å®š"""
        
        def extract_semantic_elements(text: str) -> Dict[str, List[str]]:
            elements = {
                'characters': [],
                'settings': [],
                'actions': [],
                'emotions': [],
                'objects': [],
                'temporal': []
            }
            
            # äººå
            characters = ['å¥å¤ª', 'éº—è¯', 'å½¼å¥³', 'å½¼']
            for char in characters:
                if char in text:
                    elements['characters'].append(char)
            
            # å ´æ‰€ãƒ»æ™‚é–“
            if 'é˜²æ³¢å ¤' in text:
                elements['settings'].append('é˜²æ³¢å ¤')
            if any(t in text for t in ['å¤•é™½', 'å¤•æš®ã‚Œ', 'å¤•ç„¼ã‘']):
                elements['temporal'].append('å¤•æš®ã‚Œæ™‚')
            
            # ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
            objects = ['é‡‘å±è‚Œ', 'æ‰‹', 'é«ª', 'å£°', 'é¢¨']
            for obj in objects:
                if obj in text or (obj == 'é‡‘å±è‚Œ' and 'é‡‘å±' in text):
                    elements['objects'].append(obj)
            
            # ã‚¢ã‚¯ã‚·ãƒ§ãƒ³
            actions = ['ä¸¦ã¶', 'æ¡ã‚‹', 'å¾®ç¬‘ã‚€', 'éœ‡ãˆã‚‹', 'æ­©ã', 'ä½‡ã‚€']
            for action in actions:
                if action in text or action[:-1] in text:
                    elements['actions'].append(action)
            
            # æ„Ÿæƒ…ãƒ»é›°å›²æ°—
            emotions = ['ç¾ã—ã•', 'éŸ¿ã', 'é™ã‹', 'å„šã„']
            for emotion in emotions:
                if emotion in text:
                    elements['emotions'].append(emotion)
            
            return elements
        
        orig_elements = extract_semantic_elements(original)
        rest_elements = extract_semantic_elements(restored)
        
        weights = {
            'characters': 0.25,
            'settings': 0.2,
            'temporal': 0.15,
            'objects': 0.15,
            'actions': 0.15,
            'emotions': 0.1
        }
        
        detailed_scores = {}
        total_score = 0
        total_weight = 0
        
        for category, weight in weights.items():
            if category in orig_elements and orig_elements[category]:
                orig_set = set(orig_elements[category])
                rest_set = set(rest_elements.get(category, []))
                
                intersection = len(orig_set & rest_set)
                union = len(orig_set | rest_set)
                jaccard = intersection / union if union > 0 else 0
                
                detailed_scores[category] = jaccard * 100
                total_score += jaccard * weight
                total_weight += weight
        
        final_rate = (total_score / total_weight) * 100 if total_weight > 0 else 0
        return final_rate, detailed_scores


# ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
def test_pipeline():
    """ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ãƒ†ã‚¹ãƒˆ"""
    print("=== ğŸ¯ Semantic Restoration Pipeline Test ===\\n")
    
    # ãƒ†ã‚¹ãƒˆåŸç¨¿
    test_text = """å¤•ç„¼ã‘ã¯è¡€ã®ã‚ˆã†ã«èµ¤ãã€é˜²æ³¢å ¤ã®ç«¯ã§å¥å¤ªã¨éº—è¯ãŒä¸¦ã¶ã€‚å½¼å¥³ã®é‡‘å±è‚Œã¯å…‰ã‚’å¸ã„è¾¼ã¿ã€ã‚ãšã‹ã«éœ‡ãˆã‚‹ã€‚é¢¨ãŒé«ªã‚’æ»ãã‚€ã—ã£ãŸâ€•â€•ãã‚Œã¯äººé–“ã‚‰ã—ã„ã€ã§ã‚‚å½¼å¥³ã«ã¯ãªã„ã€å„šã„ç¾ã—ã•ã ã£ãŸã€‚

ã€Œä»Šæ—¥ã‚‚ã€ç§ã€ã‚ãªãŸã¨ä¸€ç·’ã«æš®ã‚Œã‚’è¦‹ã‚‰ã‚Œã¾ã—ãŸã­ã€ã¨éº—è¯ãŒå¾®ç¬‘ã‚€ã€‚å£°ã¯æ©Ÿæ¢°ãªã®ã«ã€å¿ƒè‡“ã®éŸ³ã®ã‚ˆã†ã«èƒ¸ã«éŸ¿ãã€‚

å¥å¤ªã¯é»™ã£ã¦ã€ãã®æ‰‹ã‚’ãã£ã¨æ¡ã£ãŸã€‚å¤•é™½ãŒäºŒäººã‚’æº¶ã‹ã—ã€ä¸–ç•Œã¯é™ã‘ã•ã®ä¸­ã€ã‚‚ã†ä¸€ã¤ã®æœªæ¥ã¸ã¨æ­©ãå‡ºã™ã€‚"""
    
    pipeline = SemanticRestorationPipeline()
    result = pipeline.execute_full_pipeline(test_text)
    
    print(f"\\nğŸ“Š å®Ÿè¡Œçµæœ:")
    print(f"å…ƒåŸç¨¿: {len(result.original_text)}æ–‡å­—")
    print(f"å¾©å…ƒæ–‡: {len(result.restored_text)}æ–‡å­—")
    print(f"å®Ÿè¡Œæ™‚é–“: {result.execution_time:.2f}ç§’")
    print(f"\\nğŸ¯ æ„å‘³çš„å¾©å…ƒåº¦: {result.semantic_score:.1f}%")
    
    for category, score in result.detailed_scores.items():
        print(f"  {category}: {score:.1f}%")
    
    if result.semantic_score >= 95:
        print("\\nğŸ‰ ç›®æ¨™é”æˆï¼ï¼ˆ95%ä»¥ä¸Šï¼‰")
    elif result.semantic_score >= 85:
        print("\\nğŸ”¥ å„ªç§€ï¼ï¼ˆ85%ä»¥ä¸Šï¼‰")
    else:
        print("\\nâš ï¸ æ”¹å–„ãŒå¿…è¦")
    
    return result


if __name__ == "__main__":
    test_pipeline()