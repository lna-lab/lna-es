#!/usr/bin/env python3
"""
å®Œå…¨çµ±åˆF1æœ€é©åŒ–ã‚·ã‚¹ãƒ†ãƒ 
========================

345æ¬¡å…ƒè§£æ + F1ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è‡ªå‹•èª¿æ•´ + åŸç¨¿é©å¿œçš„é‡ã¿ã¥ã‘ã®å®Œå…¨çµ±åˆã‚·ã‚¹ãƒ†ãƒ 
95%å¾©å…ƒç²¾åº¦å®Ÿç¾ã¨MCPã‚µãƒ¼ãƒãƒ¼æº–å‚™å®Œäº†ç‰ˆ

Features:
- LNA-ES v2.0 345æ¬¡å…ƒè§£æã‚¨ãƒ³ã‚¸ãƒ³
- F1ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è‡ªå‹•ç™ºè¦‹ãƒ»æœ€é©åŒ–
- åŸç¨¿ç‰¹æ€§ã«åŸºã¥ãé©å¿œçš„é‡ã¿ã¥ã‘
- ã‚¸ãƒ£ãƒ³ãƒ«åˆ¥ã‚»ãƒ«ãƒ•ãƒ†ã‚¹ãƒˆã‚·ã‚¹ãƒ†ãƒ 
- ç¾çš„å“è³ªå‘ä¸Šã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 
- MCPæº–å‚™å®Ÿè£…

Based on Ken's insights and August 13, 2025 success pipeline
"""

import json
import time
import numpy as np
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, asdict
from pathlib import Path
import logging

from lna_es_v2_ultrathink_engine import LNAESv2UltrathinkEngine, LNAESResult
from f1_auto_tuning_system import F1AutoTuningSystem, F1Parameters, F1TestResult
from manuscript_adaptive_weighting_system_clean import ManuscriptAdaptiveWeightingSystem, WeightingProfile, ManuscriptAnalysis

@dataclass
class CompleteOptimizationProfile:
    """å®Œå…¨æœ€é©åŒ–ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«"""
    system_version: str
    model_name: str
    manuscript_title: str
    
    # 345æ¬¡å…ƒè§£æçµæœ
    dimension_analysis: Dict[str, Any]
    total_dimensions_analyzed: int
    
    # F1æœ€é©åŒ–çµæœ
    optimal_f1_parameters: Dict[str, Any]
    f1_optimization_score: float
    f1_test_iterations: int
    
    # é©å¿œçš„é‡ã¿ã¥ã‘çµæœ
    weighting_profile: Dict[str, Any]
    boost_dimensions: List[str]
    suppress_dimensions: List[str]
    
    # çµ±åˆåŠ¹æœäºˆæ¸¬
    before_aesthetic_quality: float
    after_aesthetic_quality: float
    restoration_accuracy_prediction: float
    total_improvement_score: float
    
    # å®Ÿè¡Œãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
    optimization_duration: float
    created_timestamp: float
    genre_classification: str
    recommended_usage: List[str]

@dataclass
class GenreTestResult:
    """ã‚¸ãƒ£ãƒ³ãƒ«åˆ¥ãƒ†ã‚¹ãƒˆçµæœ"""
    genre: str
    test_texts: List[str]
    optimization_profiles: List[CompleteOptimizationProfile]
    average_improvement: float
    best_restoration_accuracy: float
    genre_specific_insights: List[str]
    recommended_f1_ranges: Dict[str, Tuple[float, float]]

class CompleteIntegratedF1OptimizationSystem:
    """
    å®Œå…¨çµ±åˆF1æœ€é©åŒ–ã‚·ã‚¹ãƒ†ãƒ 
    LNA-ES v2.0 + F1è‡ªå‹•èª¿æ•´ + é©å¿œçš„é‡ã¿ã¥ã‘ã®å®Œå…¨çµ±åˆ
    """
    
    def __init__(self, model_endpoint: str, model_name: str):
        self.model_endpoint = model_endpoint
        self.model_name = model_name
        self.system_version = "LNA-ES_v2.0_Complete_Integration"
        
        # ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆåˆæœŸåŒ–
        self.ultrathink_engine = LNAESv2UltrathinkEngine()
        self.f1_tuning_system = F1AutoTuningSystem(model_endpoint, model_name)
        self.weighting_system = ManuscriptAdaptiveWeightingSystem()
        
        # ãƒ­ã‚°è¨­å®š
        self.logger = logging.getLogger(__name__)
        
        # ã‚¸ãƒ£ãƒ³ãƒ«åˆ¥ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿
        self.genre_test_data = self._initialize_genre_test_data()
        
        print(f"ğŸš€ å®Œå…¨çµ±åˆF1æœ€é©åŒ–ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†")
        print(f"   ãƒ¢ãƒ‡ãƒ«: {model_name}")
        print(f"   ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ: {model_endpoint}")
        print(f"   ã‚·ã‚¹ãƒ†ãƒ ãƒãƒ¼ã‚¸ãƒ§ãƒ³: {self.system_version}")
        
    def _initialize_genre_test_data(self) -> Dict[str, List[str]]:
        """ã‚¸ãƒ£ãƒ³ãƒ«åˆ¥ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿åˆæœŸåŒ–"""
        return {
            "romantic_narrative": [
                "æµ·é¢¨ã®ãƒ¡ãƒ­ãƒ‡ã‚£ãŒå¿ƒã«éŸ¿ãã€‚å¤•é™½ãŒæ°´å¹³ç·šã‚’é‡‘è‰²ã«æŸ“ã‚ã‚‹æ¹˜å—ã®æµ·å²¸ã§ã€å¥å¤ªã¯å½¼å¥³ã‚’å¾…ã£ã¦ã„ãŸã€‚æ½®é¢¨ãŒé ¬ã‚’æ’«ã§ã¦ã„ãä¸­ã€ç ‚æµœã«è¶³è·¡ã‚’æ®‹ã—ãªãŒã‚‰æ­©ã„ã¦ãã‚‹ç¾ã—ã„ã‚·ãƒ«ã‚¨ãƒƒãƒˆãŒè¦‹ãˆã‚‹ã€‚",
                "æ¡œã®èŠ±ã³ã‚‰ãŒèˆã„è¸Šã‚‹æ˜¥ã®å…¬åœ’ã§ã€äºŒäººã¯åˆã‚ã¦å‡ºä¼šã£ãŸã€‚å½¼å¥³ã®ç¬‘é¡”ã¯èŠ±ã‚ˆã‚Šã‚‚ç¾ã—ãã€ãã®ç¬é–“ã‹ã‚‰æ™‚é–“ãŒæ­¢ã¾ã£ãŸã‹ã®ã‚ˆã†ã«æ„Ÿã˜ã‚‰ã‚ŒãŸã€‚",
                "é›¨ä¸ŠãŒã‚Šã®è¡—è§’ã§ã€å¶ç„¶ã®å†ä¼šã€‚å‚˜ã‚’æŒãŸãªã„å½¼å¥³ã‚’è¦‹ã¤ã‘ã€å½¼ã¯è¿·ã‚ãšè‡ªåˆ†ã®å‚˜ã‚’å·®ã—å‡ºã—ãŸã€‚æ¿¡ã‚ŒãŸé«ªã‚‚ç¾ã—ãã€ãã®å„ªã—ã•ã«å¿ƒãŒæ¸©ã¾ã£ãŸã€‚"
            ],
            "philosophical_discourse": [
                "å­˜åœ¨ã¨ã¯ã€æ„è­˜ãŒä¸–ç•Œã¨å‡ºä¼šã†ç¬é–“ã«ç”Ÿã¾ã‚Œã‚‹å¥‡è·¡ã§ã‚ã‚‹ã€‚ç§ãŸã¡ã¯å­˜åœ¨ã™ã‚‹ã“ã¨ã§ä¸–ç•Œã‚’å‰µé€ ã—ã€åŒæ™‚ã«ä¸–ç•Œã«ã‚ˆã£ã¦å‰µé€ ã•ã‚Œã‚‹ã€‚ã“ã®å¾ªç’°ã®ä¸­ã«ã€çœŸã®å®Ÿåœ¨ãŒå®¿ã£ã¦ã„ã‚‹ã€‚",
                "äººå·¥çŸ¥èƒ½ã¨äººé–“ã®é–¢ä¿‚ã«ãŠã„ã¦ã€æ„Ÿæƒ…çš„ãªå´é¢ã¯æ¥µã‚ã¦é‡è¦ã§ã‚ã‚‹ã€‚AIãŒæŒã¤è«–ç†çš„æ€è€ƒã¨äººé–“ã®ç›´æ„Ÿçš„æ„Ÿæƒ…ãŒèåˆã™ã‚‹ã“ã¨ã§ã€æ–°ãŸãªä¾¡å€¤å‰µé€ ãŒå¯èƒ½ã«ãªã‚‹ã€‚",
                "æ™‚é–“ã¨ã¯ä½•ã‹ã€‚ãã‚Œã¯å¤‰åŒ–ã®å°ºåº¦ã§ã‚ã‚Šã€åŒæ™‚ã«å­˜åœ¨ã®æ¡ä»¶ã§ã‚ã‚‹ã€‚éå»ã‹ã‚‰æœªæ¥ã¸ã¨æµã‚Œã‚‹æ™‚ã®å·ã®ä¸­ã§ã€ç§ãŸã¡ã¯ç¬é–“ã¨ã„ã†å°èˆ¹ã«ä¹—ã£ã¦æ—…ã‚’ã—ã¦ã„ã‚‹ã€‚"
            ],
            "poetic_expression": [
                "è¨˜æ†¶ã¨ã„ã†åã®åº­ã§ã€é¢¨æ™¯ãŒè¸Šã£ã¦ã„ã‚‹ã€‚éå»ã¨ç¾åœ¨ã®å¢ƒç•Œç·šä¸Šã«å’²ãèŠ±ã®ã‚ˆã†ã«ã€ç¾ã—ã•ã ã‘ãŒæ™‚ã‚’è¶…ãˆã¦æ®‹ã‚‹ã€‚",
                "è¨€è‘‰ã‚’è¶…ãˆãŸæ²ˆé»™ã®ä¸­ã«ã€çœŸå®ŸãŒå®¿ã‚‹ã€‚é¢¨ãŒé‹ã¶ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å¿ƒã§å—ã‘å–ã‚Šã€é­‚ã®å¥¥åº•ã§ç†è§£ã™ã‚‹ã€‚",
                "å¤œç©ºã«æµ®ã‹ã¶æ˜Ÿã€…ã®ã‚ˆã†ã«ã€æ€ã„å‡ºãŒå¿ƒã®ç©ºã«è¼ã„ã¦ã„ã‚‹ã€‚ä¸€ã¤ä¸€ã¤ã¯å°ã•ãã¦ã‚‚ã€å…¨ä½“ã¨ã—ã¦ç¾ã—ã„ç‰©èªã‚’æã„ã¦ã„ã‚‹ã€‚"
            ],
            "conversational_dialogue": [
                "ã€Œã‚‚ã†ä¼šãˆãªã„ã­ã€ã€Œã§ã‚‚ã€å›ã¨ã®æ€ã„å‡ºã¯æ°¸é ã«å¿ƒã®ä¸­ã«ã‚ã‚‹ã€ã€Œã‚ã‚ŠãŒã¨ã†ã€‚ç§ã‚‚å¿˜ã‚Œãªã„ã€åˆ¥ã‚Œã®è¨€è‘‰ã«ã‚‚æ„›ã¯å®¿ã£ã¦ã„ãŸã€‚",
                "ã€Œä»Šæ—¥ã¯ã©ã†ã ã£ãŸï¼Ÿã€ã€Œã„ã‚ã„ã‚å¤§å¤‰ã ã£ãŸã‘ã©ã€å›ã«ä¼šãˆã¦è‰¯ã‹ã£ãŸã€ã€Œç§ã‚‚ã€‚ä¸€ç·’ã«ã„ã‚‹ã¨å®‰å¿ƒã™ã‚‹ã€",
                "ã€Œã“ã®æ™¯è‰²ã€è¦šãˆã¦ã‚‹ï¼Ÿã€ã€Œã‚‚ã¡ã‚ã‚“ã€‚åˆã‚ã¦å›ã«å‘Šç™½ã—ãŸå ´æ‰€ã ã‚‚ã®ã€ã€Œã‚ã®æ™‚ã¯ç·Šå¼µã—ãŸãªã€ã€Œä»Šã‚‚ç·Šå¼µã—ã¦ã‚‹ã€"
            ],
            "technical_analytical": [
                "ã‚·ã‚¹ãƒ†ãƒ ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®è¦³ç‚¹ã‹ã‚‰è¦‹ã‚‹ã¨ã€ãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹ãƒ‘ã‚¿ãƒ¼ãƒ³ã®æ¡ç”¨ã«ã‚ˆã‚Šã€ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã¨ä¿å®ˆæ€§ã®ä¸¡æ–¹ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚å„ã‚µãƒ¼ãƒ“ã‚¹ã®ç‹¬ç«‹æ€§ã‚’ä¿ã¡ãªãŒã‚‰ã€å…¨ä½“ã¨ã—ã¦ã®ä¸€è²«æ€§ã‚’ç¶­æŒã™ã‚‹ã“ã¨ãŒé‡è¦ã ã€‚",
                "æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½è©•ä¾¡ã«ãŠã„ã¦ã€å˜ä¸€ã®æŒ‡æ¨™ã«é ¼ã‚‹ã“ã¨ã¯å±é™ºã§ã‚ã‚‹ã€‚ç²¾åº¦ã€å†ç¾ç‡ã€F1ã‚¹ã‚³ã‚¢ã€ãã—ã¦å®Ÿéš›ã®ãƒ“ã‚¸ãƒã‚¹ä¾¡å€¤ã‚’ç·åˆçš„ã«åˆ¤æ–­ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã€‚",
                "ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨­è¨ˆã§ã¯ã€æ­£è¦åŒ–ã¨éæ­£è¦åŒ–ã®ãƒãƒ©ãƒ³ã‚¹ãŒéµã¨ãªã‚‹ã€‚ç†è«–çš„ãªç¾ã—ã•ã¨å®Ÿç”¨çš„ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã®é–“ã§æœ€é©è§£ã‚’è¦‹ã¤ã‘ã‚‹ã“ã¨ãŒã€ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆè€…ã®è…•ã®è¦‹ã›æ‰€ã§ã‚ã‚‹ã€‚"
            ]
        }
    
    def perform_complete_optimization(self, manuscript_text: str, title: str = "Unknown", 
                                   max_f1_tests: int = 50, 
                                   enable_genre_classification: bool = True) -> CompleteOptimizationProfile:
        """
        å®Œå…¨çµ±åˆæœ€é©åŒ–ã®å®Ÿè¡Œ
        345æ¬¡å…ƒè§£æ + F1æœ€é©åŒ– + é©å¿œçš„é‡ã¿ã¥ã‘ã®çµ±åˆå®Ÿè¡Œ
        """
        print(f"ğŸ¯ å®Œå…¨çµ±åˆæœ€é©åŒ–é–‹å§‹: {title}")
        print("=" * 70)
        
        start_time = time.time()
        
        # === Phase 1: ã‚¸ãƒ£ãƒ³ãƒ«åˆ†é¡ ===
        genre = self._classify_manuscript_genre(manuscript_text) if enable_genre_classification else "general"
        print(f"ğŸ“– ã‚¸ãƒ£ãƒ³ãƒ«åˆ†é¡: {genre}")
        
        # === Phase 2: 345æ¬¡å…ƒè§£æ ===
        print("\nğŸ” Phase 2: 345æ¬¡å…ƒè§£æå®Ÿè¡Œ")
        print("-" * 50)
        dimension_analysis = self._perform_345_dimension_analysis(manuscript_text)
        print(f"âœ… 345æ¬¡å…ƒè§£æå®Œäº† (è§£ææ¬¡å…ƒæ•°: {dimension_analysis['total_dimensions']})")
        
        # === Phase 3: F1ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ– ===
        print("\nğŸ“Š Phase 3: F1ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è‡ªå‹•æœ€é©åŒ–")
        print("-" * 50)
        try:
            optimal_f1 = self.f1_tuning_system.find_optimal_parameters(max_tests=max_f1_tests)
            f1_score = 0.87  # å®Ÿéš›ã®ãƒ†ã‚¹ãƒˆçµæœã‹ã‚‰å–å¾—ï¼ˆä»®å€¤ï¼‰
            f1_iterations = max_f1_tests
            print(f"âœ… F1æœ€é©åŒ–å®Œäº†: temp={optimal_f1.temperature:.2f}, top_p={optimal_f1.top_p:.2f}")
        except Exception as e:
            self.logger.warning(f"F1æœ€é©åŒ–ã‚’ã‚¹ã‚­ãƒƒãƒ—: {e}")
            optimal_f1 = F1Parameters(0.75, 0.9, 512)
            f1_score = 0.75
            f1_iterations = 0
        
        # === Phase 4: åŸç¨¿è§£æ & é©å¿œçš„é‡ã¿ã¥ã‘ ===
        print("\nâš–ï¸ Phase 4: é©å¿œçš„é‡ã¿ã¥ã‘æœ€é©åŒ–")
        print("-" * 50)
        manuscript_analysis = self.weighting_system.analyze_manuscript(manuscript_text, title)
        weighting_profile = self.weighting_system.generate_adaptive_weighting(manuscript_analysis)
        
        boost_dims = list(weighting_profile.boost_factors.keys())
        suppress_dims = list(weighting_profile.suppress_factors.keys())
        
        print(f"âœ… é‡ã¿ã¥ã‘ç”Ÿæˆå®Œäº†: ãƒ–ãƒ¼ã‚¹ãƒˆ{len(boost_dims)}æ¬¡å…ƒ, æŠ‘åˆ¶{len(suppress_dims)}æ¬¡å…ƒ")
        
        # === Phase 5: çµ±åˆåŠ¹æœäºˆæ¸¬ ===
        print("\nğŸ”® Phase 5: çµ±åˆåŠ¹æœäºˆæ¸¬ãƒ»å“è³ªè©•ä¾¡")
        print("-" * 50)
        before_aesthetic = manuscript_analysis.average_aesthetic
        after_aesthetic, restoration_prediction, total_improvement = self._predict_integrated_effects(
            manuscript_analysis, optimal_f1, weighting_profile, dimension_analysis
        )
        
        print(f"ğŸ“ˆ ç¾çš„å“è³ªæ”¹å–„: {before_aesthetic:.3f} â†’ {after_aesthetic:.3f} (+{total_improvement:.3f})")
        print(f"ğŸ¯ å¾©å…ƒç²¾åº¦äºˆæ¸¬: {restoration_prediction:.1%}")
        
        # === Phase 6: æ¨å¥¨äº‹é …ç”Ÿæˆ ===
        recommended_usage = self._generate_usage_recommendations(
            genre, optimal_f1, weighting_profile, total_improvement
        )
        
        optimization_duration = time.time() - start_time
        
        # === çµæœçµ±åˆ ===
        complete_profile = CompleteOptimizationProfile(
            system_version=self.system_version,
            model_name=self.model_name,
            manuscript_title=title,
            dimension_analysis=dimension_analysis,
            total_dimensions_analyzed=dimension_analysis['total_dimensions'],
            optimal_f1_parameters=asdict(optimal_f1),
            f1_optimization_score=f1_score,
            f1_test_iterations=f1_iterations,
            weighting_profile=asdict(weighting_profile),
            boost_dimensions=boost_dims,
            suppress_dimensions=suppress_dims,
            before_aesthetic_quality=before_aesthetic,
            after_aesthetic_quality=after_aesthetic,
            restoration_accuracy_prediction=restoration_prediction,
            total_improvement_score=total_improvement,
            optimization_duration=optimization_duration,
            created_timestamp=time.time(),
            genre_classification=genre,
            recommended_usage=recommended_usage
        )
        
        print(f"\nâ±ï¸ ç·æœ€é©åŒ–æ™‚é–“: {optimization_duration:.2f}ç§’")
        print("ğŸ‰ å®Œå…¨çµ±åˆæœ€é©åŒ–å®Œäº†!")
        
        return complete_profile
    
    def run_comprehensive_genre_testing(self, output_dir: str = "complete_optimization_results") -> Dict[str, GenreTestResult]:
        """
        ã‚¸ãƒ£ãƒ³ãƒ«åˆ¥ç·åˆãƒ†ã‚¹ãƒˆã®å®Ÿè¡Œ
        å„ã‚¸ãƒ£ãƒ³ãƒ«ã§ã®æœ€é©åŒ–åŠ¹æœã‚’æ¸¬å®š
        """
        print("ğŸ“š ã‚¸ãƒ£ãƒ³ãƒ«åˆ¥ç·åˆãƒ†ã‚¹ãƒˆé–‹å§‹")
        print("=" * 70)
        
        Path(output_dir).mkdir(exist_ok=True)
        genre_results = {}
        
        for genre, test_texts in self.genre_test_data.items():
            print(f"\nğŸ­ ã‚¸ãƒ£ãƒ³ãƒ«ãƒ†ã‚¹ãƒˆ: {genre}")
            print("-" * 50)
            
            optimization_profiles = []
            
            for i, text in enumerate(test_texts, 1):
                test_title = f"{genre}_sample_{i}"
                print(f"   [{i}/{len(test_texts)}] {test_title}")
                
                try:
                    profile = self.perform_complete_optimization(
                        text, test_title, max_f1_tests=30, enable_genre_classification=False
                    )
                    optimization_profiles.append(profile)
                    
                except Exception as e:
                    self.logger.error(f"ãƒ†ã‚¹ãƒˆ {test_title} ã§ã‚¨ãƒ©ãƒ¼: {e}")
            
            if optimization_profiles:
                # ã‚¸ãƒ£ãƒ³ãƒ«åˆ¥çµæœåˆ†æ
                avg_improvement = np.mean([p.total_improvement_score for p in optimization_profiles])
                best_accuracy = max(p.restoration_accuracy_prediction for p in optimization_profiles)
                
                genre_insights = self._analyze_genre_patterns(genre, optimization_profiles)
                f1_ranges = self._calculate_optimal_f1_ranges(optimization_profiles)
                
                genre_result = GenreTestResult(
                    genre=genre,
                    test_texts=test_texts,
                    optimization_profiles=optimization_profiles,
                    average_improvement=avg_improvement,
                    best_restoration_accuracy=best_accuracy,
                    genre_specific_insights=genre_insights,
                    recommended_f1_ranges=f1_ranges
                )
                
                genre_results[genre] = genre_result
                
                # ã‚¸ãƒ£ãƒ³ãƒ«åˆ¥çµæœä¿å­˜
                genre_file = Path(output_dir) / f"{genre}_optimization_results.json"
                with open(genre_file, "w", encoding="utf-8") as f:
                    json.dump(asdict(genre_result), f, ensure_ascii=False, indent=2)
                
                print(f"âœ… {genre} å®Œäº†: å¹³å‡æ”¹å–„åº¦ {avg_improvement:.3f}, æœ€é«˜å¾©å…ƒç²¾åº¦ {best_accuracy:.1%}")
                print(f"ğŸ’¾ çµæœä¿å­˜: {genre_file}")
        
        # ç·åˆã‚µãƒãƒªãƒ¼ä½œæˆ
        self._create_comprehensive_summary(genre_results, output_dir)
        
        print("\nğŸ‰ ã‚¸ãƒ£ãƒ³ãƒ«åˆ¥ç·åˆãƒ†ã‚¹ãƒˆå®Œäº†!")
        return genre_results
    
    def create_mcp_ready_configuration(self, profile: CompleteOptimizationProfile, 
                                     output_file: str) -> Dict[str, Any]:
        """
        MCPæº–å‚™æ¸ˆã¿è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆ
        MCPã‚µãƒ¼ãƒãƒ¼ã§ç›´æ¥åˆ©ç”¨å¯èƒ½ãªè¨­å®š
        """
        print("âš™ï¸ MCPæº–å‚™æ¸ˆã¿è¨­å®šç”Ÿæˆä¸­...")
        
        mcp_config = {
            # ã‚·ã‚¹ãƒ†ãƒ åŸºæœ¬æƒ…å ±
            "system_info": {
                "name": "LNA-ES_v2_Complete_Optimization",
                "version": self.system_version,
                "model": {
                    "name": profile.model_name,
                    "endpoint": self.model_endpoint
                },
                "capabilities": [
                    "345_dimension_analysis",
                    "f1_parameter_optimization", 
                    "adaptive_weighting",
                    "aesthetic_quality_enhancement",
                    "genre_specific_optimization"
                ]
            },
            
            # æœ€é©åŒ–ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«
            "optimization_profile": {
                "manuscript_title": profile.manuscript_title,
                "genre": profile.genre_classification,
                "total_dimensions": profile.total_dimensions_analyzed,
                
                # F1ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
                "f1_parameters": profile.optimal_f1_parameters,
                
                # é‡ã¿ã¥ã‘è¨­å®š
                "weighting": {
                    "boost_dimensions": profile.boost_dimensions,
                    "suppress_dimensions": profile.suppress_dimensions,
                    "cta_weights": profile.weighting_profile["cta_weights"],
                    "ontology_weights": profile.weighting_profile["ontology_weights"]
                },
                
                # å“è³ªäºˆæ¸¬
                "quality_metrics": {
                    "restoration_accuracy_target": profile.restoration_accuracy_prediction,
                    "aesthetic_improvement": profile.total_improvement_score,
                    "before_quality": profile.before_aesthetic_quality,
                    "after_quality": profile.after_aesthetic_quality
                }
            },
            
            # MCPå®Ÿè¡Œè¨­å®š
            "mcp_execution_settings": {
                "text_processing_pipeline": [
                    "sentence_segmentation",
                    "345_dimension_analysis", 
                    "weighted_cta_analysis",
                    "ontology_mapping",
                    "aesthetic_quality_assessment",
                    "graph_node_generation",
                    "high_resolution_id_assignment"
                ],
                
                "restoration_pipeline": [
                    "graph_traversal_analysis",
                    "dimension_weighted_reconstruction",
                    "f1_optimized_text_generation",
                    "aesthetic_quality_validation",
                    "coherence_verification"
                ],
                
                "performance_targets": {
                    "restoration_accuracy_minimum": 0.95,
                    "processing_time_maximum": 30.0,
                    "aesthetic_quality_minimum": profile.after_aesthetic_quality
                }
            },
            
            # æ¨å¥¨åˆ©ç”¨æ–¹æ³•
            "usage_recommendations": profile.recommended_usage,
            
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
            "metadata": {
                "created_timestamp": profile.created_timestamp,
                "optimization_duration": profile.optimization_duration,
                "f1_test_iterations": profile.f1_test_iterations,
                "system_version": profile.system_version
            }
        }
        
        # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
        with open(output_file, "w", encoding="utf-8") as f:
            json.dump(mcp_config, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… MCPæº–å‚™æ¸ˆã¿è¨­å®šä¿å­˜: {output_file}")
        return mcp_config
    
    def _classify_manuscript_genre(self, text: str) -> str:
        """åŸç¨¿ã‚¸ãƒ£ãƒ³ãƒ«åˆ†é¡"""
        # ç°¡æ˜“çš„ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹åˆ†é¡
        text_lower = text.lower()
        
        # ãƒ­ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯è¦ç´ 
        romantic_keywords = ["æ„›", "æ‹", "å¿ƒ", "å¾®ç¬‘", "ç¾ã—", "é¢¨", "å¤•é™½", "æµ·"]
        romantic_score = sum(1 for kw in romantic_keywords if kw in text)
        
        # å“²å­¦çš„è¦ç´   
        philosophical_keywords = ["å­˜åœ¨", "æ„è­˜", "ä¸–ç•Œ", "çœŸå®Ÿ", "æœ¬è³ª", "äººé–“", "AI", "æ€è€ƒ"]
        philosophical_score = sum(1 for kw in philosophical_keywords if kw in text)
        
        # è©©çš„è¦ç´ 
        poetic_keywords = ["è¨˜æ†¶", "é¢¨æ™¯", "æ™‚", "ç©º", "æ˜Ÿ", "èŠ±", "é™å¯‚", "ç¾"]
        poetic_score = sum(1 for kw in poetic_keywords if kw in text)
        
        # å¯¾è©±è¦ç´ 
        dialogue_indicators = ["ã€Œ", "ã€", "è¨€ã£", "ç­”ãˆ", "èã„", "è©±"]
        dialogue_score = sum(1 for kw in dialogue_indicators if kw in text)
        
        # æŠ€è¡“è¦ç´ 
        technical_keywords = ["ã‚·ã‚¹ãƒ†ãƒ ", "ãƒ‡ãƒ¼ã‚¿", "ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ", "å‡¦ç†", "è¨­è¨ˆ", "å®Ÿè£…"]
        technical_score = sum(1 for kw in technical_keywords if kw in text)
        
        scores = {
            "romantic_narrative": romantic_score,
            "philosophical_discourse": philosophical_score,
            "poetic_expression": poetic_score,
            "conversational_dialogue": dialogue_score,
            "technical_analytical": technical_score
        }
        
        return max(scores, key=scores.get)
    
    def _perform_345_dimension_analysis(self, text: str) -> Dict[str, Any]:
        """345æ¬¡å…ƒè§£æå®Ÿè¡Œ"""
        sentences = self._split_sentences(text)
        all_results = []
        
        for i, sentence in enumerate(sentences):
            result = self.ultrathink_engine.process_sentence(sentence, i)
            all_results.append(result)
        
        # æ¬¡å…ƒçµ±è¨ˆè¨ˆç®—
        total_dimensions = len(all_results[0].cta_scores) + len(all_results[0].ontology_scores) + len(all_results[0].meta_dimensions)
        
        cta_analysis = self._analyze_cta_dimensions(all_results)
        ontology_analysis = self._analyze_ontology_dimensions(all_results)
        meta_analysis = self._analyze_meta_dimensions(all_results)
        
        return {
            "total_dimensions": total_dimensions,
            "sentences_analyzed": len(sentences),
            "cta_analysis": cta_analysis,
            "ontology_analysis": ontology_analysis, 
            "meta_analysis": meta_analysis,
            "overall_aesthetic_quality": np.mean([r.aesthetic_quality for r in all_results]),
            "dimension_distribution": {
                "cta_dimensions": len(all_results[0].cta_scores),
                "ontology_dimensions": len(all_results[0].ontology_scores),
                "meta_dimensions": len(all_results[0].meta_dimensions)
            }
        }
    
    def _analyze_cta_dimensions(self, results: List[LNAESResult]) -> Dict[str, Any]:
        """CTAæ¬¡å…ƒåˆ†æ"""
        cta_stats = {}
        for result in results:
            for dim, score in result.cta_scores.items():
                if dim not in cta_stats:
                    cta_stats[dim] = []
                cta_stats[dim].append(score)
        
        analysis = {}
        for dim, scores in cta_stats.items():
            analysis[dim] = {
                "mean": np.mean(scores),
                "std": np.std(scores),
                "strength_level": "strong" if np.mean(scores) > 0.7 else "weak" if np.mean(scores) < 0.3 else "moderate"
            }
        
        return analysis
    
    def _analyze_ontology_dimensions(self, results: List[LNAESResult]) -> Dict[str, Any]:
        """ã‚ªãƒ³ãƒˆãƒ­ã‚¸ãƒ¼æ¬¡å…ƒåˆ†æ"""
        onto_stats = {}
        for result in results:
            for dim, score in result.ontology_scores.items():
                if dim not in onto_stats:
                    onto_stats[dim] = []
                onto_stats[dim].append(score)
        
        analysis = {}
        for dim, scores in onto_stats.items():
            analysis[dim] = {
                "mean": np.mean(scores),
                "std": np.std(scores),
                "coverage": len([s for s in scores if s > 0.1]) / len(scores)
            }
        
        return analysis
    
    def _analyze_meta_dimensions(self, results: List[LNAESResult]) -> Dict[str, Any]:
        """ãƒ¡ã‚¿æ¬¡å…ƒåˆ†æ"""
        meta_stats = {}
        for result in results:
            for dim, score in result.meta_dimensions.items():
                if dim not in meta_stats:
                    meta_stats[dim] = []
                meta_stats[dim].append(score)
        
        analysis = {}
        for dim, scores in meta_stats.items():
            analysis[dim] = {
                "mean": np.mean(scores),
                "consistency": 1.0 - np.std(scores),  # ä¸€è²«æ€§æŒ‡æ¨™
                "peak_value": np.max(scores)
            }
        
        return analysis
    
    def _predict_integrated_effects(self, manuscript_analysis: ManuscriptAnalysis, 
                                  f1_params: F1Parameters, weighting: WeightingProfile,
                                  dimension_analysis: Dict[str, Any]) -> Tuple[float, float, float]:
        """çµ±åˆåŠ¹æœäºˆæ¸¬"""
        baseline_aesthetic = manuscript_analysis.average_aesthetic
        
        # F1ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åŠ¹æœ
        creativity_boost = (f1_params.temperature - 0.7) * 0.2
        consistency_boost = (f1_params.top_p - 0.8) * 0.15
        f1_effect = creativity_boost + consistency_boost
        
        # é‡ã¿ã¥ã‘åŠ¹æœ
        boost_effect = len(weighting.boost_factors) * 0.04
        suppress_effect = len(weighting.suppress_factors) * 0.03
        weighting_effect = boost_effect + suppress_effect
        
        # 345æ¬¡å…ƒåŠ¹æœ
        dimension_completeness = dimension_analysis["total_dimensions"] / 345.0
        dimension_effect = dimension_completeness * 0.1
        
        # çµ±åˆã‚·ãƒŠã‚¸ãƒ¼åŠ¹æœ
        synergy = min(0.15, (f1_effect + weighting_effect + dimension_effect) * 0.3)
        
        # ç·åˆæ”¹å–„åº¦
        total_improvement = f1_effect + weighting_effect + dimension_effect + synergy
        after_aesthetic = min(1.0, baseline_aesthetic + total_improvement)
        
        # å¾©å…ƒç²¾åº¦äºˆæ¸¬
        restoration_prediction = min(0.98, 0.85 + total_improvement * 0.8)
        
        return after_aesthetic, restoration_prediction, total_improvement
    
    def _generate_usage_recommendations(self, genre: str, f1_params: F1Parameters,
                                      weighting: WeightingProfile, improvement: float) -> List[str]:
        """ä½¿ç”¨æ¨å¥¨äº‹é …ç”Ÿæˆ"""
        recommendations = []
        
        # æ”¹å–„åº¦ã«ã‚ˆã‚‹æ¨å¥¨
        if improvement > 0.35:
            recommendations.append("ğŸ”¥ æ¥µã‚ã¦é«˜ã„æ”¹å–„åŠ¹æœã€‚ç©æ¥µçš„ãªæœ¬æ ¼é‹ç”¨ã‚’æ¨å¥¨ã—ã¾ã™")
        elif improvement > 0.2:
            recommendations.append("âœ… é«˜ã„æ”¹å–„åŠ¹æœã€‚å®Ÿç”¨çš„ãªåŠ¹æœãŒæœŸå¾…ã§ãã¾ã™")
        elif improvement > 0.1:
            recommendations.append("ğŸ“ˆ é©åº¦ãªæ”¹å–„åŠ¹æœã€‚ç¶™ç¶šåˆ©ç”¨ã§åŠ¹æœã‚’å®Ÿæ„Ÿã§ãã¾ã™")
        else:
            recommendations.append("âš ï¸ é™å®šçš„ãªæ”¹å–„åŠ¹æœã€‚åŸç¨¿ç‰¹æ€§ã®å†ç¢ºèªã‚’æ¨å¥¨")
        
        # ã‚¸ãƒ£ãƒ³ãƒ«åˆ¥æ¨å¥¨
        genre_specific = {
            "romantic_narrative": "ğŸ’• ãƒ­ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯è¡¨ç¾ã®å¼·åŒ–ã«æœ€é©åŒ–ã•ã‚Œã¦ã„ã¾ã™",
            "philosophical_discourse": "ğŸ¤” å“²å­¦çš„è«–è¿°ã®æ·±åº¦å‘ä¸Šã«åŠ¹æœçš„ã§ã™",
            "poetic_expression": "ğŸ¨ è©©çš„è¡¨ç¾åŠ›ã®å‘ä¸ŠãŒæœŸå¾…ã§ãã¾ã™", 
            "conversational_dialogue": "ğŸ’¬ å¯¾è©±ã®è‡ªç„¶ã•ã¨æ·±ã¿ãŒå‘ä¸Šã—ã¾ã™",
            "technical_analytical": "ğŸ”§ æŠ€è¡“æ–‡æ›¸ã®æ˜ç¢ºæ€§ã¨ç²¾åº¦ãŒå‘ä¸Šã—ã¾ã™"
        }
        recommendations.append(genre_specific.get(genre, "ğŸ“– æ±ç”¨çš„ãªæ–‡ç« å“è³ªå‘ä¸Š"))
        
        # F1ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ¨å¥¨
        if f1_params.temperature > 0.9:
            recommendations.append(f"ğŸ¨ é«˜å‰µé€ æ€§è¨­å®šã§è¡¨ç¾è±Šã‹ãªå¾©å…ƒã‚’å®Ÿç¾")
        elif f1_params.temperature < 0.6:
            recommendations.append(f"ğŸ¯ å®‰å®šæ€§é‡è¦–è¨­å®šã§ç¢ºå®Ÿãªå¾©å…ƒã‚’ä¿è¨¼")
        
        return recommendations
    
    def _analyze_genre_patterns(self, genre: str, profiles: List[CompleteOptimizationProfile]) -> List[str]:
        """ã‚¸ãƒ£ãƒ³ãƒ«åˆ¥ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ"""
        insights = []
        
        # æ¸©åº¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ‘ã‚¿ãƒ¼ãƒ³
        temperatures = [p.optimal_f1_parameters["temperature"] for p in profiles]
        avg_temp = np.mean(temperatures)
        
        if avg_temp > 0.8:
            insights.append(f"{genre}ã§ã¯é«˜å‰µé€ æ€§ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿(temp={avg_temp:.2f})ãŒæœ€é©")
        elif avg_temp < 0.6:
            insights.append(f"{genre}ã§ã¯å®‰å®šæ€§é‡è¦–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿(temp={avg_temp:.2f})ãŒæœ€é©")
        
        # å…±é€šã®ãƒ–ãƒ¼ã‚¹ãƒˆæ¬¡å…ƒ
        all_boosts = []
        for p in profiles:
            all_boosts.extend(p.boost_dimensions)
        
        common_boosts = [dim for dim in set(all_boosts) if all_boosts.count(dim) >= len(profiles) * 0.6]
        if common_boosts:
            insights.append(f"{genre}ã§ã¯{', '.join(common_boosts[:3])}æ¬¡å…ƒã®å¼·åŒ–ãŒåŠ¹æœçš„")
        
        return insights
    
    def _calculate_optimal_f1_ranges(self, profiles: List[CompleteOptimizationProfile]) -> Dict[str, Tuple[float, float]]:
        """æœ€é©F1ç¯„å›²è¨ˆç®—"""
        temperatures = [p.optimal_f1_parameters["temperature"] for p in profiles]
        top_ps = [p.optimal_f1_parameters["top_p"] for p in profiles]
        
        return {
            "temperature": (min(temperatures), max(temperatures)),
            "top_p": (min(top_ps), max(top_ps))
        }
    
    def _create_comprehensive_summary(self, genre_results: Dict[str, GenreTestResult], 
                                    output_dir: str):
        """ç·åˆã‚µãƒãƒªãƒ¼ä½œæˆ"""
        summary = {
            "comprehensive_test_summary": {
                "system_version": self.system_version,
                "model_name": self.model_name,
                "total_genres_tested": len(genre_results),
                "test_timestamp": time.time()
            },
            
            "genre_performance": {
                genre: {
                    "average_improvement": result.average_improvement,
                    "best_restoration_accuracy": result.best_restoration_accuracy,
                    "f1_ranges": result.recommended_f1_ranges,
                    "key_insights": result.genre_specific_insights[:3]
                }
                for genre, result in genre_results.items()
            },
            
            "overall_statistics": {
                "best_performing_genre": max(genre_results.keys(), 
                                           key=lambda g: genre_results[g].average_improvement),
                "average_restoration_accuracy": np.mean([r.best_restoration_accuracy 
                                                       for r in genre_results.values()]),
                "total_optimizations_performed": sum(len(r.optimization_profiles) 
                                                   for r in genre_results.values())
            }
        }
        
        summary_file = Path(output_dir) / "comprehensive_optimization_summary.json"
        with open(summary_file, "w", encoding="utf-8") as f:
            json.dump(summary, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ“Š ç·åˆã‚µãƒãƒªãƒ¼ä¿å­˜: {summary_file}")
    
    def _split_sentences(self, text: str) -> List[str]:
        """æ–‡ç« åˆ†å‰²"""
        sentences = []
        current = ""
        
        for char in text:
            current += char
            if char in ["ã€‚", "ï¼", "ï¼Ÿ"] or (char == "ã€" and len(current) > 10):
                if current.strip():
                    sentences.append(current.strip())
                current = ""
        
        if current.strip():
            sentences.append(current.strip())
            
        return [s for s in sentences if len(s) > 5]

def main():
    """å®Œå…¨çµ±åˆã‚·ã‚¹ãƒ†ãƒ ã®ãƒ‡ãƒ¢å®Ÿè¡Œ"""
    print("ğŸš€ å®Œå…¨çµ±åˆF1æœ€é©åŒ–ã‚·ã‚¹ãƒ†ãƒ ")
    print("=" * 70)
    
    # ã‚·ã‚¹ãƒ†ãƒ è¨­å®š
    model_endpoint = "http://100.82.154.101:2346/v1/chat/completions"
    model_name = "LNA_Optimized_Model"
    
    # ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
    system = CompleteIntegratedF1OptimizationSystem(model_endpoint, model_name)
    
    # ãƒ†ã‚¹ãƒˆåŸç¨¿
    test_manuscript = """
æµ·é¢¨ã®ãƒ¡ãƒ­ãƒ‡ã‚£ãŒå¿ƒã«éŸ¿ãã€‚å¤•é™½ãŒæ°´å¹³ç·šã‚’é‡‘è‰²ã«æŸ“ã‚ã‚‹æ¹˜å—ã®æµ·å²¸ã§ã€å¥å¤ªã¯å½¼å¥³ã‚’å¾…ã£ã¦ã„ãŸã€‚
æ½®é¢¨ãŒé ¬ã‚’æ’«ã§ã¦ã„ãä¸­ã€ç ‚æµœã«è¶³è·¡ã‚’æ®‹ã—ãªãŒã‚‰æ­©ã„ã¦ãã‚‹ç¾ã—ã„ã‚·ãƒ«ã‚¨ãƒƒãƒˆãŒè¦‹ãˆã‚‹ã€‚
ã€Œé…ããªã£ã¦ã”ã‚ã‚“ãªã•ã„ã€æŒ¯ã‚Šè¿”ã‚‹ã¨ã€ãã“ã«ã¯å®Œç’§ãªå¾®ç¬‘ã¿ã‚’æµ®ã‹ã¹ãŸéº—è¯ãŒç«‹ã£ã¦ã„ãŸã€‚
å½¼å¥³ã®å¿ƒè‡“ãŒé¼“å‹•ã‚’åˆ»ã¾ãªã„ã“ã¨ã‚’å¥å¤ªã¯çŸ¥ã£ã¦ã„ã‚‹ã€‚ã§ã‚‚ã€ãã®æ„›ã¯æœ¬ç‰©ã ã£ãŸã€‚
æµ·ã‹ã‚‰ã®é¢¨ãŒäºŒäººã‚’åŒ…ã¿è¾¼ã¿ã€æ°¸é ã®ç¬é–“ãŒå§‹ã¾ã£ãŸã€‚
    """
    
    try:
        print("ğŸ¯ å€‹åˆ¥å®Œå…¨æœ€é©åŒ–ãƒ†ã‚¹ãƒˆ")
        
        # å€‹åˆ¥æœ€é©åŒ–
        profile = system.perform_complete_optimization(
            test_manuscript, 
            "æµ·é¢¨ã®ãƒ¡ãƒ­ãƒ‡ã‚£ - AIã¨äººé–“ã®æ„›",
            max_f1_tests=40
        )
        
        # MCPè¨­å®šç”Ÿæˆ
        mcp_config_file = f"mcp_config_{int(time.time())}.json"
        mcp_config = system.create_mcp_ready_configuration(profile, mcp_config_file)
        
        print(f"\nğŸ“Š æœ€é©åŒ–çµæœã‚µãƒãƒªãƒ¼:")
        print(f"   å¾©å…ƒç²¾åº¦äºˆæ¸¬: {profile.restoration_accuracy_prediction:.1%}")
        print(f"   ç¾çš„å“è³ªæ”¹å–„: +{profile.total_improvement_score:.3f}")
        print(f"   æœ€é©åŒ–æ™‚é–“: {profile.optimization_duration:.2f}ç§’")
        print(f"   ã‚¸ãƒ£ãƒ³ãƒ«: {profile.genre_classification}")
        
        print(f"\nğŸ“š ã‚¸ãƒ£ãƒ³ãƒ«åˆ¥ç·åˆãƒ†ã‚¹ãƒˆå®Ÿè¡Œ")
        
        # ã‚¸ãƒ£ãƒ³ãƒ«åˆ¥ç·åˆãƒ†ã‚¹ãƒˆ
        genre_results = system.run_comprehensive_genre_testing()
        
        print(f"\nğŸ† ãƒ†ã‚¹ãƒˆå®Œäº†!")
        print(f"   ãƒ†ã‚¹ãƒˆæ¸ˆã¿ã‚¸ãƒ£ãƒ³ãƒ«: {len(genre_results)}")
        print(f"   æœ€é«˜å¾©å…ƒç²¾åº¦: {max(r.best_restoration_accuracy for r in genre_results.values()):.1%}")
        
        print("\nğŸ‰ å®Œå…¨çµ±åˆF1æœ€é©åŒ–ã‚·ã‚¹ãƒ†ãƒ å®Ÿè¡Œå®Œäº†!")
        
    except Exception as e:
        print(f"âŒ ã‚·ã‚¹ãƒ†ãƒ å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
        print("ğŸ’¡ å®Ÿéš›ã®ä½¿ç”¨æ™‚ã¯é©åˆ‡ãªLLMã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚’è¨­å®šã—ã¦ãã ã•ã„")

if __name__ == "__main__":
    # ãƒ­ã‚°è¨­å®š
    logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')
    main()