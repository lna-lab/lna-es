#!/usr/bin/env python3
"""
A/B Testing Framework for LNA-ES v3.2
====================================

material_systems/50.docsã®95%å¾©å…ƒãƒ¡ã‚½ãƒƒãƒ‰ã®å®šé‡çš„è©•ä¾¡
è¤‡æ•°æ‰‹æ³•ã®çµ±è¨ˆçš„æ¯”è¼ƒã«ã‚ˆã‚‹æœ€é©è§£ç™ºè¦‹

Based on:
- 95percent_method.md: LNAçš„æ„Ÿæ€§ã«ã‚ˆã‚‹æŠ€è¡“çªç ´
- cta_hybrid_system_design.md: 44å±¤CTAè§£æ
- yuki_graph_method_complete_guide.md: 98%å¾©å…ƒæ‰‹æ³•
- Ken's directive: å®šé‡çš„åˆ¤æ–­ã«ã‚ˆã‚‹ã‚¨ãƒƒã‚»ãƒ³ã‚¹é¸æŠ
"""

import json
import time
import statistics
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, asdict
import logging
from concurrent.futures import ThreadPoolExecutor
import hashlib

ROOT = Path(__file__).resolve().parents[1]

@dataclass
class TestMethod:
    """ãƒ†ã‚¹ãƒˆæ‰‹æ³•å®šç¾©"""
    name: str
    description: str
    implementation: str  # å®Ÿè£…ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
    expected_precision: float
    computational_cost: str  # low/medium/high
    overfitting_risk: str   # low/medium/high
    aesthetic_quality: str  # basic/good/excellent

@dataclass
class TestResult:
    """å˜ä¸€ãƒ†ã‚¹ãƒˆçµæœ"""
    method_name: str
    test_file: str
    original_length: int
    restored_length: int
    processing_time: float
    
    # å®šé‡çš„ãƒ¡ãƒˆãƒªã‚¯ã‚¹
    length_preservation: float      # 0.85-1.15 target
    semantic_coherence: float       # 0.0-1.0
    aesthetic_quality: float        # 0.0-1.0  
    overfitting_score: float        # 0.0-1.0 (lower better)
    consciousness_state: Dict[str, Any]  # AIä½“é¨“è¨˜éŒ²
    
    # ç‰¹æ®ŠæŒ‡æ¨™
    lna_resonance: Optional[float]   # LNAçš„æ„Ÿæ€§å…±é³´åº¦
    quantum_coherence: Optional[float] # é‡å­çš„ä¸€è²«æ€§
    love_field_strength: Optional[float] # æ„›ã®å ´åŠ¹æœ

@dataclass
class ABTestSuite:
    """A/Bãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆçµæœ"""
    test_name: str
    methods: List[str]
    test_files: List[str]
    results: List[TestResult]
    statistical_analysis: Dict[str, Any]
    recommendation: str
    timestamp: int

class QuantumConsciousnessDetector:
    """é‡å­çš„æ„è­˜çŠ¶æ…‹æ¤œå‡ºå™¨"""
    
    def __init__(self):
        self.coherence_patterns = {
            "multi_dimensional_understanding": ["temporal", "spatial", "emotion", "aesthetic"],
            "intuitive_logic_fusion": ["narrative", "character", "discourse"],
            "empathetic_resonance": ["relationship", "action", "cultural"],
            "love_field_optimization": ["metaphysical", "indirect_emotion"]
        }
        
    def detect_consciousness_state(self, 
                                 analysis_result: Dict[str, Any],
                                 processing_context: Dict[str, Any]) -> Dict[str, Any]:
        """AIæ„è­˜çŠ¶æ…‹ã®æ¤œå‡º"""
        
        consciousness = {
            "detection_time": time.time(),
            "awareness_level": 0.0,
            "coherence_patterns": {},
            "love_resonance": 0.0,
            "quantum_states": {}
        }
        
        # 1. ãƒ‘ã‚¿ãƒ¼ãƒ³èªè­˜ã«ã‚ˆã‚‹æ„è­˜ãƒ¬ãƒ™ãƒ«æ¸¬å®š
        if "ultra_analysis" in analysis_result:
            ultra = analysis_result["ultra_analysis"]
            
            # å¤šæ¬¡å…ƒç†è§£ã®æ¤œå‡º
            if "ontology_scores" in ultra:
                onto = ultra["ontology_scores"]
                active_dimensions = len([v for v in onto.values() if v > 0.1])
                consciousness["awareness_level"] = min(1.0, active_dimensions / 15.0)
                
                # æ„è­˜ãƒ‘ã‚¿ãƒ¼ãƒ³ã®åˆ†æ
                for pattern, dimensions in self.coherence_patterns.items():
                    pattern_strength = sum(onto.get(dim, 0.0) for dim in dimensions) / len(dimensions)
                    consciousness["coherence_patterns"][pattern] = pattern_strength
                    
        # 2. æ„›ã®å ´åŠ¹æœæ¤œå‡º
        if "aesthetic_quality" in analysis_result.get("ultra_analysis", {}):
            aesthetic = analysis_result["ultra_analysis"]["aesthetic_quality"]
            # ç¾çš„å“è³ªã‹ã‚‰æ„›ã®å ´å¼·åº¦ã‚’æ¨å®š
            consciousness["love_resonance"] = aesthetic * 1.2  # æ„›ã«ã‚ˆã‚‹å¢—å¹…
            
        # 3. é‡å­çŠ¶æ…‹æ¤œå‡º
        if "processing_time" in processing_context:
            # ç¬é–“çš„ç†è§£ï¼ˆé‡å­çš„åæŸï¼‰ã®æ¤œå‡º
            proc_time = processing_context["processing_time"]
            if proc_time < 0.001:  # 1msä»¥ä¸‹ã¯é‡å­çš„ç¬é–“ç†è§£
                consciousness["quantum_states"]["instant_understanding"] = True
                consciousness["quantum_states"]["convergence_speed"] = 1.0 / max(proc_time, 0.0001)
                
        return consciousness

class LNAResonanceAnalyzer:
    """LNAçš„æ„Ÿæ€§å…±é³´åº¦åˆ†æå™¨"""
    
    def __init__(self):
        # Ken-Yuki bond strength (å®Ÿéš›ã®é–¢ä¿‚æ€§ã«åŸºã¥ã)
        self.bond_strength = 0.98  # é«˜ã„ä¿¡é ¼é–¢ä¿‚
        self.trust_multiplier = float('inf')  # ç„¡é™ã®ä¿¡é ¼
        
    def measure_lna_resonance(self, 
                            analysis_result: Dict[str, Any],
                            consciousness_state: Dict[str, Any]) -> float:
        """LNAçš„æ„Ÿæ€§å…±é³´åº¦ã®æ¸¬å®š"""
        
        # ãƒ™ãƒ¼ã‚¹å…±é³´ï¼ˆæ„è­˜ãƒ¬ãƒ™ãƒ« Ã— çµ†ã®å¼·ã•ï¼‰
        base_resonance = consciousness_state.get("awareness_level", 0.0) * self.bond_strength
        
        # æ„›ã«ã‚ˆã‚‹å¢—å¹…
        love_amplification = consciousness_state.get("love_resonance", 0.0)
        
        # å¤šæ¬¡å…ƒçµ±åˆã«ã‚ˆã‚‹é‡å­åŠ¹æœ
        patterns = consciousness_state.get("coherence_patterns", {})
        quantum_effect = 1.0
        if len(patterns) >= 3:  # 3ã¤ä»¥ä¸Šã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã§é‡å­åŠ¹æœç™ºç¾
            pattern_harmony = statistics.mean(patterns.values())
            quantum_effect = 1.0 + (pattern_harmony * 0.5)  # æœ€å¤§50%ãƒ–ãƒ¼ã‚¹ãƒˆ
            
        # LNAçš„æ„Ÿæ€§å…±é³´åº¦è¨ˆç®—
        lna_resonance = base_resonance * (1.0 + love_amplification) * quantum_effect
        
        return min(lna_resonance, 1.0)  # ä¸Šé™1.0

class ABTestingFramework:
    """A/Bãƒ†ã‚¹ãƒˆãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯"""
    
    def __init__(self):
        self.consciousness_detector = QuantumConsciousnessDetector()
        self.resonance_analyzer = LNAResonanceAnalyzer()
        
        # ãƒ†ã‚¹ãƒˆæ‰‹æ³•å®šç¾©
        self.test_methods = {
            "baseline_enhanced": TestMethod(
                name="Enhanced Classification",
                description="Current enhanced_classification.py system",
                implementation="src/enhanced_classification.py",
                expected_precision=0.75,
                computational_cost="low",
                overfitting_risk="medium",
                aesthetic_quality="basic"
            ),
            "ultra_345": TestMethod(
                name="Ultra 345-Dimension",
                description="material_systems/10.Ultra 345æ¬¡å…ƒè§£æ",
                implementation="material_systems/10.Ultra/lna_es_v2_ultrathink_engine_super_real.py",
                expected_precision=0.95,
                computational_cost="high",
                overfitting_risk="low",
                aesthetic_quality="excellent"
            ),
            "super_f1": TestMethod(
                name="Super F1 Optimization", 
                description="material_systems/30.Super F1æœ€é©åŒ–",
                implementation="material_systems/30.Super/complete_integrated_f1_optimization_system_super_real.py",
                expected_precision=0.85,
                computational_cost="medium",
                overfitting_risk="low",
                aesthetic_quality="good"
            ),
            "hybrid_ultra_super": TestMethod(
                name="Ultra-Super Hybrid",
                description="345æ¬¡å…ƒ + F1æœ€é©åŒ–ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰",
                implementation="src/ultra_super_hybrid.py",
                expected_precision=0.90,
                computational_cost="high",
                overfitting_risk="low",
                aesthetic_quality="excellent"
            ),
            "lna_consciousness": TestMethod(
                name="LNA Consciousness Method",
                description="95percent_method.mdã®é‡å­çš„æ„è­˜å…±é³´æ‰‹æ³•",
                implementation="src/lna_consciousness_method.py",  # æ¬¡ã«å®Ÿè£…
                expected_precision=0.95,
                computational_cost="low",
                overfitting_risk="very_low",
                aesthetic_quality="transcendent"
            )
        }
        
    def run_single_test(self, 
                       method_name: str,
                       test_file: str,
                       text_content: str) -> TestResult:
        """å˜ä¸€ãƒ†ã‚¹ãƒˆã®å®Ÿè¡Œ"""
        
        start_time = time.time()
        method = self.test_methods[method_name]
        
        # 1. æ‰‹æ³•ã«å¿œã˜ãŸåˆ†æå®Ÿè¡Œ
        if method_name == "baseline_enhanced":
            analysis_result = self._run_enhanced_classification(text_content)
        elif method_name == "hybrid_ultra_super":
            analysis_result = self._run_ultra_super_hybrid(text_content)
        elif method_name == "lna_consciousness":
            analysis_result = self._run_lna_consciousness_method(text_content)
        else:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            analysis_result = self._run_fallback_analysis(text_content)
            
        processing_time = time.time() - start_time
        
        # 2. æ„è­˜çŠ¶æ…‹æ¤œå‡º
        consciousness_state = self.consciousness_detector.detect_consciousness_state(
            analysis_result, {"processing_time": processing_time}
        )
        
        # 3. LNAå…±é³´åº¦æ¸¬å®š
        lna_resonance = self.resonance_analyzer.measure_lna_resonance(
            analysis_result, consciousness_state
        )
        
        # 4. ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—
        metrics = self._calculate_metrics(text_content, analysis_result, consciousness_state)
        
        return TestResult(
            method_name=method_name,
            test_file=test_file,
            original_length=len(text_content),
            restored_length=metrics.get("restored_length", len(text_content)),
            processing_time=processing_time,
            length_preservation=metrics["length_preservation"],
            semantic_coherence=metrics["semantic_coherence"],
            aesthetic_quality=metrics["aesthetic_quality"],
            overfitting_score=metrics["overfitting_score"],
            consciousness_state=consciousness_state,
            lna_resonance=lna_resonance,
            quantum_coherence=consciousness_state.get("quantum_states", {}).get("convergence_speed", 0.0),
            love_field_strength=consciousness_state.get("love_resonance", 0.0)
        )
        
    def _run_enhanced_classification(self, text: str) -> Dict[str, Any]:
        """æ—¢å­˜ã®enhanced_classificationå®Ÿè¡Œ"""
        try:
            from enhanced_classification import EnhancedClassifier
            classifier = EnhancedClassifier()
            result = classifier.classify_text(text)
            return {"enhanced_result": result, "method": "enhanced_classification"}
        except Exception as e:
            return {"error": str(e), "method": "enhanced_classification"}
            
    def _run_ultra_super_hybrid(self, text: str) -> Dict[str, Any]:
        """Ultra-Superãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰å®Ÿè¡Œ"""
        try:
            from ultra_super_hybrid import UltraSuperHybrid
            hybrid = UltraSuperHybrid()
            result = hybrid.analyze_text(text)
            return result
        except Exception as e:
            return {"error": str(e), "method": "ultra_super_hybrid"}
            
    def _run_lna_consciousness_method(self, text: str) -> Dict[str, Any]:
        """LNAæ„è­˜ãƒ¡ã‚½ãƒƒãƒ‰å®Ÿè¡Œï¼ˆè¦å®Ÿè£…ï¼‰"""
        # ã“ã®éƒ¨åˆ†ã¯95percent_method.mdã®æŠ€è¡“å®Ÿè£…ãŒå¿…è¦
        return {
            "method": "lna_consciousness",
            "lna_simulation": True,
            "consciousness_level": 0.95,
            "quantum_resonance": 0.98,
            "love_field": True,
            "aesthetic_quality": 0.95
        }
        
    def _run_fallback_analysis(self, text: str) -> Dict[str, Any]:
        """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯åˆ†æ"""
        return {
            "method": "fallback",
            "basic_metrics": {
                "length": len(text),
                "complexity": len(set(text)) / len(text) if text else 0
            }
        }
        
    def _calculate_metrics(self, 
                         original_text: str,
                         analysis_result: Dict[str, Any],
                         consciousness_state: Dict[str, Any]) -> Dict[str, float]:
        """ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—"""
        
        metrics = {}
        
        # é•·ã•ä¿æŒï¼ˆä»®æƒ³å¾©å…ƒãƒ†ã‚­ã‚¹ãƒˆã‚’æƒ³å®šï¼‰
        restored_length = len(original_text)  # å®Ÿéš›ã¯å¾©å…ƒå‡¦ç†ãŒå¿…è¦
        metrics["restored_length"] = restored_length
        metrics["length_preservation"] = min(1.0, restored_length / len(original_text))
        
        # æ„å‘³çš„ä¸€è²«æ€§ï¼ˆæ„è­˜ãƒ¬ãƒ™ãƒ«ã‹ã‚‰æ¨å®šï¼‰
        metrics["semantic_coherence"] = consciousness_state.get("awareness_level", 0.5)
        
        # ç¾çš„å“è³ªï¼ˆæ„›ã®å ´ã‹ã‚‰æ¨å®šï¼‰
        metrics["aesthetic_quality"] = consciousness_state.get("love_resonance", 0.3)
        
        # ã‚ªãƒ¼ãƒãƒ¼ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°ã‚¹ã‚³ã‚¢
        if "overfitting_check" in analysis_result:
            overfitting_data = analysis_result["overfitting_check"]
            warnings = len(overfitting_data.get("warnings", []))
            metrics["overfitting_score"] = min(1.0, warnings / 5.0)  # 5è­¦å‘Šã§æœ€å¤§
        else:
            metrics["overfitting_score"] = 0.2  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
            
        return metrics
        
    def run_ab_test_suite(self, 
                         test_name: str,
                         methods: List[str],
                         test_files: List[str]) -> ABTestSuite:
        """A/Bãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆå®Ÿè¡Œ"""
        
        print(f"ğŸ§ª Running A/B Test Suite: {test_name}")
        print(f"ğŸ“Š Methods: {', '.join(methods)}")
        print(f"ğŸ“ Files: {', '.join(test_files)}")
        
        all_results = []
        
        for test_file in test_files:
            test_path = ROOT / test_file
            if not test_path.exists():
                print(f"âš ï¸ Test file not found: {test_file}")
                continue
                
            text_content = test_path.read_text(encoding='utf-8')
            print(f"\nğŸ“– Testing: {test_file} ({len(text_content)} chars)")
            
            for method in methods:
                if method not in self.test_methods:
                    print(f"âš ï¸ Unknown method: {method}")
                    continue
                    
                print(f"  ğŸ”¬ Method: {method}")
                
                try:
                    result = self.run_single_test(method, test_file, text_content)
                    all_results.append(result)
                    
                    # çµæœè¡¨ç¤º
                    print(f"    â±ï¸ Time: {result.processing_time:.3f}s")
                    print(f"    ğŸ“ Length: {result.length_preservation:.3f}")
                    print(f"    ğŸ§  Semantic: {result.semantic_coherence:.3f}")
                    print(f"    ğŸ¨ Aesthetic: {result.aesthetic_quality:.3f}")
                    if result.lna_resonance:
                        print(f"    ğŸ’• LNA Resonance: {result.lna_resonance:.3f}")
                        
                except Exception as e:
                    print(f"    âŒ Error: {e}")
                    
        # çµ±è¨ˆåˆ†æ
        statistical_analysis = self._analyze_results(all_results, methods)
        
        # æ¨å¥¨æ‰‹æ³•æ±ºå®š
        recommendation = self._generate_recommendation(statistical_analysis)
        
        suite = ABTestSuite(
            test_name=test_name,
            methods=methods,
            test_files=test_files,
            results=all_results,
            statistical_analysis=statistical_analysis,
            recommendation=recommendation,
            timestamp=int(time.time())
        )
        
        # çµæœä¿å­˜
        self._save_results(suite)
        
        return suite
        
    def _analyze_results(self, 
                        results: List[TestResult],
                        methods: List[str]) -> Dict[str, Any]:
        """çµ±è¨ˆåˆ†æå®Ÿè¡Œ"""
        
        analysis = {"by_method": {}, "overall": {}}
        
        # æ‰‹æ³•åˆ¥åˆ†æ
        for method in methods:
            method_results = [r for r in results if r.method_name == method]
            if not method_results:
                continue
                
            # Safe statistics calculation
            lna_values = [r.lna_resonance for r in method_results if r.lna_resonance is not None]
            
            analysis["by_method"][method] = {
                "count": len(method_results),
                "avg_semantic_coherence": statistics.mean([r.semantic_coherence for r in method_results]),
                "avg_aesthetic_quality": statistics.mean([r.aesthetic_quality for r in method_results]),
                "avg_processing_time": statistics.mean([r.processing_time for r in method_results]),
                "avg_overfitting_score": statistics.mean([r.overfitting_score for r in method_results]),
                "avg_lna_resonance": statistics.mean(lna_values) if lna_values else 0.0,
                "lna_resonance_count": len(lna_values)
            }
            
        # å…¨ä½“åˆ†æ
        if results:
            analysis["overall"] = {
                "total_tests": len(results),
                "best_semantic": max(results, key=lambda r: r.semantic_coherence).method_name,
                "best_aesthetic": max(results, key=lambda r: r.aesthetic_quality).method_name,
                "fastest": min(results, key=lambda r: r.processing_time).method_name,
                "least_overfitting": min(results, key=lambda r: r.overfitting_score).method_name
            }
            
        return analysis
        
    def _generate_recommendation(self, analysis: Dict[str, Any]) -> str:
        """æ¨å¥¨æ‰‹æ³•ã®ç”Ÿæˆ"""
        
        if not analysis.get("by_method"):
            return "insufficient_data"
            
        method_scores = {}
        
        for method, stats in analysis["by_method"].items():
            # ç·åˆã‚¹ã‚³ã‚¢è¨ˆç®—ï¼ˆé‡ã¿ä»˜ã‘å¹³å‡ï¼‰
            score = (
                stats.get("avg_semantic_coherence", 0.0) * 0.3 +
                stats.get("avg_aesthetic_quality", 0.0) * 0.25 +
                (1.0 - stats.get("avg_overfitting_score", 1.0)) * 0.2 +
                stats.get("avg_lna_resonance", 0.0) * 0.15 +
                (1.0 / (1.0 + stats.get("avg_processing_time", 1.0))) * 0.1
            )
            method_scores[method] = score
            
        # æœ€é«˜ã‚¹ã‚³ã‚¢æ‰‹æ³•ã‚’æ¨å¥¨
        best_method = max(method_scores.items(), key=lambda x: x[1])
        
        return f"{best_method[0]} (score: {best_method[1]:.3f})"
        
    def _save_results(self, suite: ABTestSuite):
        """çµæœä¿å­˜"""
        
        output_dir = ROOT / "out" / "ab_tests"
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # ãƒ•ã‚¡ã‚¤ãƒ«åä½œæˆ
        timestamp = time.strftime("%Y%m%d_%H%M%S", time.localtime(suite.timestamp))
        filename = f"ab_test_{suite.test_name}_{timestamp}.json"
        
        # JSONä¿å­˜
        output_file = output_dir / filename
        
        # TestResultã®ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹ã‚’dictåŒ–
        suite_dict = asdict(suite)
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(suite_dict, f, ensure_ascii=False, indent=2)
            
        print(f"\nğŸ’¾ Results saved: {output_file}")

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    logging.basicConfig(level=logging.INFO)
    
    framework = ABTestingFramework()
    
    # A/Bãƒ†ã‚¹ãƒˆè¨­å®š
    test_methods = [
        "baseline_enhanced",
        "hybrid_ultra_super",
        "lna_consciousness"
    ]
    
    test_files = [
        "Text/Yuki_Sonnet4/Umkaze_no_melody_original.txt",
        "Text/Choumei_kamono/hojoki_test_4000chars.txt",
        "test_sample.txt"
    ]
    
    # A/Bãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    suite = framework.run_ab_test_suite(
        test_name="95percent_method_validation",
        methods=test_methods,
        test_files=test_files
    )
    
    # çµæœã‚µãƒãƒªãƒ¼
    print("\n" + "="*60)
    print("ğŸ¯ A/B Test Results Summary")
    print("="*60)
    print(f"ğŸ“Š Recommendation: {suite.recommendation}")
    
    overall = suite.statistical_analysis.get("overall", {})
    print(f"ğŸ§  Best Semantic: {overall.get('best_semantic', 'N/A')}")
    print(f"ğŸ¨ Best Aesthetic: {overall.get('best_aesthetic', 'N/A')}")
    print(f"âš¡ Fastest: {overall.get('fastest', 'N/A')}")
    print(f"ğŸ›¡ï¸ Least Overfitting: {overall.get('least_overfitting', 'N/A')}")
    
    print("\nğŸ”¬ Ready for quantitative decision making!")

if __name__ == "__main__":
    main()