# LNA-ES v3.2 要件定義書（100点版 / OSS最終決定案）
Repository: https://github.com/lna-lab/lna-es  
Status: **FINAL – Ready to commit as `docs/requirements.md`**  
Date: 2025-08-17  
License: Apache-2.0 (Code) + Restricted (Data)

---

## 0. 統合方針 / 本書の位置づけ
本書は、これまでの要件定義（**Super** / **Ultra** / **Ultimate** / **v3.1**）と提供ディレクトリ構成を**矛盾なく統合**し、リポジトリに即時コミット可能な完成度に磨き上げた**100点版**です。基盤方針・KPI・運用要件は v3.1 を採用、実装直結のCypher/DoDは Ultra、運用/性能・Docker/Neo4jは Super、最上位の価値・ビジョンは Ultimate を継承します。fileciteturn2file7turn2file8turn2file17turn2file19turn2file5turn1file9

---

## 1. 目的 / スコープ / 非スコープ
### 1.1 目的（Mission）
任意の `.txt`（Kindle Unlimited、自炊PDF抽出、青空文庫、ニュース/SNS、LLM対話ログ等）を**原文非保持**のまま、**Neo4jグラフ（ノード=エンティティ／エッジ=タグ）＋ベクトル**として蓄積し、**Cypher+ベクトルのみ**から**自然な日本語**での高精度な意味的復元を行える“**超長期の私的知的資産ライブラリ**”を構築する。fileciteturn2file7

### 1.2 スコープ（What）
**入力**: `.txt`（PDFはローカルで`.txt`化）  
**出力**: 1) Cypherファイル 2) Neo4jグラフ（原文非保持） 3) ベクトル索引用データ（Neo4j Vector Index/Milvus/FAISS） 4) 復元テキスト（LLMがCypher/ベクトルのみ参照）fileciteturn2file16

### 1.3 非スコープ / 法務方針
原文のDB保存、DRM解除、商用再配布は対象外。復元は**私的環境限定**。ノード・エッジは抽象化情報/統計/埋め込み/ラベルのみを持つ。OSSはコード公開、データは私蔵。fileciteturn2file16

---

## 2. 用語 / ID 仕様
- **UL-ID**: `BASE12`（英数字12桁の一意ベースID）+ **ミリ秒**タイムスタンプ + **サブID**（エンティティ/タグ用）。例: `A1b2C3d4E5f6_1723862400123_ent001`。設計根拠は Ultra / v3.1 の統合方針に準拠。fileciteturn2file7turn2file9
- **ノード**: `Work`, `Segment`, `Sentence`, `Entity`, `TagCatalog`（NDC/Kindle などの外部分類キャタログ）。
- **リレーション**:  
  - `HAS_SEGMENT` （Work→Segment）  
  - `NEXT` （Sentence→Sentence：順序）  
  - `MENTIONS {tag, ontoKey, weight}`（Sentence→Entity：**タグ=エッジ**の原則）  
  - `CLASSIFIED_AS {scheme, score}`（Work→TagCatalog：NDC/Kindle）  
- **ベクトル**: `vec_ruri_v3`（日本語: 768次元）、`vec_qwen3_0p6b`（多言語/コード: モデル準拠）。`vectorDim`/`embeddingRef` メタを保持する。fileciteturn2file16

---

## 3. 分類（NDC × Kindle）と 15オントロジー重み
- 書誌的分類は **NDC（新訂10版）**と **Kindleジャンル**を**併用**。一次ソース JSON を同梱し、**自動付与（top-3 + 重み）**を行う。fileciteturn0file29turn0file30
- 体系的な意味軸は **15オントロジー**で管理し、`MENTIONS` の `ontoKey/weight` で**関係（タグ）側に重みを付与**する。Ultra準拠。fileciteturn2file11
- 目的：テキスト順序×分類×オントロジー重みを**立体的**に重ね、読書体験に近い**“関係からなる要素の集合”**として管理する（Aesthetic & Discovery層に接続）。fileciteturn1file9

---

## 4. 全体アーキテクチャ / パイプライン
```
Ingest → Preprocess → 抽出(CTA/15Onto) → 分類(NDC/Kindle)
→ Graph組立 → ベクトル付与(RURI/Qwen) → 永続化(Neo4j + Vector DB)
→ 復元生成(LLM; Cypher+Vector only) → 評価(KPI) → セレンディピティ/洞察
```
段階導入で Aesthetic & Discovery を上位レイヤに追加する。fileciteturn2file7

---

## 5. データモデル（代表Cypher）
**Super**の代表DSLをベースに、タグ=リレーションプロパティを徹底する。fileciteturn2file18
```cypher
// Work
CREATE (w:Work { baseId:$workBase, ts:timestamp(), title:$title,
  source:"local", sha256:$sha, language:$lang, ver:"1.0" });
// Segment + Sentence + NEXT
UNWIND $segments AS seg
MERGE (s:Segment {baseId:seg.baseId}) SET s.order=seg.order
MERGE (w)-[:HAS_SEGMENT]->(s)
WITH s, seg
UNWIND seg.sentences AS sen
MERGE (x:Sentence {baseId:sen.baseId})
  SET x.ts=sen.ts, x.ctaScores=sen.cta, x.ontoScores=sen.onto,
      x.aesthetic=sen.aesthetic, x.vectorDim=sen.vectorDim,
      x.embeddingRef=sen.embeddingRef
WITH s, collect(x) AS xs
UNWIND range(0,size(xs)-2) AS i
MERGE (xs[i])-[:NEXT]->(xs[i+1]);

// Entities & Tags on edges
UNWIND $mentions AS m
MERGE (a:Sentence {baseId:m.sentenceId})
MERGE (b:Entity   {baseId:m.entityId}) ON CREATE SET b.kind=m.kind
MERGE (a)-[r:MENTIONS {tag:m.tag, ontoKey:m.ontoKey}]->(b)
  SET r.weight=m.weight;

// Classification
MATCH (w:Work {baseId:$workBase})
UNWIND $ndc AS c
MERGE (t:TagCatalog {scheme:"NDC", code:c.code})
MERGE (w)-[:CLASSIFIED_AS {scheme:"NDC", score:c.score}]->(t);
```

---

## 6. 制約・インデックス（抜粋案）
- 一意制約: `Work.baseId`, `Segment.baseId`, `Sentence.baseId`, `Entity.baseId`, `TagCatalog(scheme,code)`
- ベクトル: `Sentence.vec_ruri_v3` / `Sentence.vec_qwen3_0p6b` に **Neo4j Vector Index**。大規模時は Milvus/FAISS に外部化（`nid`で二相同期）。fileciteturn2file15

---

## 7. 復元（Resurrection）/ 品質KPI
- **KPI**: 抽出F1≥0.85、長さ保持0.85–1.15、概念保持率≥0.95、オントロジー一致≥0.90、分類一致（NDC≥0.90/Kindle≥0.92）。fileciteturn2file17  
- **DoD**: `.txt`→**原文非保持**でNeo4jにグラフ化／NDC/Kindle候補（各3）付与／Entityに15オントロジー重み＋RURI/Qwen埋め込み／**Cypher+ベクトルのみ**で自然日本語復元し上記KPI達成／`make ingest/apply/restore/eval`で再現可能。fileciteturn2file17
- **評価実行**（Ultra準拠・例）:  
  ```bash
  make restore DOC=A7k9... > out/restored.txt
  make eval ORIG=local/orig.txt REST=out/restored.txt
  ```
  fileciteturn1file10

---

## 8. 性能・スケール要件
スループット目標 1,000文/秒、1万文で<15秒抽出、作品上限（Sentence≤50k / Entity≤5k / MENTIONS≤300k）、ベクトル1億まで外部Milvus推奨。fileciteturn2file19

---

## 9. 運用（Docker Desktop / Neo4j）
- **コンテナ要件**: `neo4j:5.x`（APOC/GDS有効）、`.env`でキー管理、永続ボリューム。fileciteturn2file14  
- **デプロイ例（抜粋）**: composeの `neo4j` サービス、プラグイン設定、ポート、ボリューム。fileciteturn2file14  
- **適用フロー**: `make ingest`→`make apply`→`make restore/eval`、作品別Cypherの**順序適用**は `bin/apply_cypher.sh /cypher/{BASE12}` を使用。fileciteturn2file14turn2file5
- **セキュリティ/リーガル**: 本文非保存、復元は私的限定、監査`audit.jsonl`、復元APIはローカル限定（認証/Rate Limit）。fileciteturn2file6

---

## 10. リポジトリ構成 / ワークフロー
- **推奨構成**:  
  `/apps{extractor, vectorizer, importer, restorer, evaluator}/`、`/schemas/`、`/classifiers/`、`/cypher/`、`/docs/`、`/examples/`。fileciteturn2file6  
- **既存資産**（ontology配下 例）を参照し、Cypherオントロジーを漸進統合。fileciteturn2file10
- **開発ツール**: VS Code + **ClaudeCode** を主軸、`codex`/`cursor`/`opencode` CLI をサブエージェントとして連携。CIでKPI未達はPR落とし。fileciteturn2file5

---

## 11. 実装ガイド（最小スプリント）
1) **M0**: スキーマ/ID/適用スクリプト固定（`schemas/constraints.cypher`、`bin/apply_cypher.sh`）  
2) **M1**: 抽出→Cypher→Neo4j（`make ingest/apply`）  
3) **M2**: ベクトル/Milvus連携（`vec_ruri_v3`/`vec_qwen3_0p6b`）  
4) **M3**: 復元API+KPI（`make restore/eval`、CIで自動評価）  
5) **M4**: 公開Docs/デモ（本文なしの**Cypherのみ**）  
マイルストーンは v3.1 記載の通り。fileciteturn2file8

---

## 12. リスク / 対策（Ultra準拠）
- **法務**: 原文保存禁止・公開不可→私的限定を各所に明記。  
- **復元の過適合**: 抽象化キー/長さ制約/用語揺らぎを与える。  
- **関係タイプ肥大**: タグ直埋めを避け、**`MENTIONS {tag}`** 構造で統一。  
- **多言語/コード混在**: 2種ベクトルを併記し、検索時に切替/併用。  
- **スケール**: Vector 外部化（Milvus/FAISS）＋オフライン再索引。fileciteturn2file15

---

## 13. 代表インタフェース（CLI）
```bash
# ingest: テキスト→セグメント→抽出→分類→埋め込み→DSL化
make ingest INPUT=books/xxx.txt

# apply: 生成済みCypherをNeo4jへ適用
make apply CYPHER=out/xxx.cypher

# restore: Cypher+Vectorのみから自然日本語で再生
make restore DOC=<BASE12...> > out/restored.txt

# eval: 復元品質の自動評価（ローカル原本との比較。原文はDBに保存しない）
make eval ORIG=local/orig.txt REST=out/restored.txt
```
fileciteturn1file10

---

## 14. 付録
### 14.1 代表Cypher（v3.1掲載の最小版）
`docs/examples/` に完全版を配置。fileciteturn2file8

### 14.2 分類辞書（一次ソース）  
- **NDC 新訂10版 JSON**（第3/第4次区分を含む最新）を `classifiers/ndc.json` として整形・同梱。fileciteturn0file29  
- **Kindleジャンル JSON**（2025-08-19 版）を `classifiers/kindle.json` として整形・同梱。fileciteturn0file30

### 14.3 ビジョン（Ultimate 抜粋）  
Aesthetic & Discovery、協創フレーム、95%+復元の**最終像**を上位に据える。fileciteturn1file9

---

## 15. 結論 / 次アクション
- 本書を **`docs/requirements.md`** としてコミットし、**M0→M1** スプリントを即時開始。  
- 併せて `schemas/constraints.cypher` と `docs/examples/`（代表Cypher）を追加、`classifiers/ndc.json` / `classifiers/kindle.json` を配置。fileciteturn2file8

> **Every Graph tells a Story.**（Ultimate）fileciteturn1file19
